---
title: "XGBoost comparison"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra) # for good looking tables

knitr::opts_chunk$set(echo = TRUE, fig.align="center")

# this allows using tikz rendering for plots with "dev=tikz"
knit_hooks$set(plot = function(x, options) {
  if ('tikz' %in% options$dev && !options$external) {
    hook_plot_tex(x, options)
  } else hook_plot_md(x, options)
})

# Fix seed for random number generator for getting consistent results in kmeans etc.
fixed_seed <- 678

# Load common MEBN package
source("mebn/MEBN.r")
```


```{r data_loading, echo=FALSE, message=FALSE}

# Read the data description
datadesc <- read.csv(file="data/SYSDIMET_data_description.csv", header = TRUE, sep = ";")

# Read the actual data matching the description
sysdimet <- read.csv(file="data/SYSDIMET_diet.csv", sep=";", dec=",")

# Define how to iterate through the graph
assumedpredictors <- datadesc[datadesc$Order==100,]    
assumedtargets <- datadesc[datadesc$Order==200,] 
```

For XGBoost, we prepare a dataset that contains all the predictors from past period (nutrients and last response), and also label that tells if the next response goes up or down.

```{r}

# Predictors for FSHDL
fshdl_input <- sysdimet

# - we assume that previous measurement from week 0 was same as week 0
fshdl_input$prev_fshdl <- fshdl_input[fshdl_input$WEEK == 0,]$fshdl

fshdl_input[fshdl_input$WEEK == 4,]$prev_fshdl <- fshdl_input[fshdl_input$WEEK == 0,]$fshdl
fshdl_input[fshdl_input$WEEK == 8,]$prev_fshdl <- fshdl_input[fshdl_input$WEEK == 4,]$fshdl
fshdl_input[fshdl_input$WEEK == 12,]$prev_fshdl <- fshdl_input[fshdl_input$WEEK == 8,]$fshdl

# try removing week 0 from training
fshdl_input <- fshdl_input[fshdl_input$WEEK >= 4,]

fshdl_input <- fshdl_input[c(as.vector(assumedpredictors$Name), "prev_fshdl")]

# Target for FSHDL 
# 0 - next FSHDL measurement is same or lower than previous
# 1 - next FSHDL measurement is higher than previous

fshdl_target <- sysdimet
fshdl_target$label <- 0

# - change of previous measurements
fshdl_target[fshdl_target$WEEK == 12,]$label <- fshdl_target[fshdl_target$WEEK == 12,]$fshdl - fshdl_target[fshdl_target$WEEK == 8,]$fshdl
fshdl_target[fshdl_target$WEEK == 8,]$label <- fshdl_target[fshdl_target$WEEK == 8,]$fshdl - fshdl_target[fshdl_target$WEEK == 4,]$fshdl
fshdl_target[fshdl_target$WEEK == 4,]$label <- fshdl_target[fshdl_target$WEEK == 4,]$fshdl - fshdl_target[fshdl_target$WEEK == 0,]$fshdl

# - we only the sign of change as label for learning
fshdl_target$label <- sign(fshdl_target$label)

fshdl_target <- fshdl_target[c("WEEK", "label")]
fshdl_target <- fshdl_target[fshdl_target$WEEK >= 4,]

# fix -1 sign to 0 label
fshdl_target[fshdl_target$label == -1,] <- 0
```


```{r}
library(xgboost)

n = nrow(fshdl_input)
train.index = sample(n,floor(0.80*n))
train.data = as.matrix(fshdl_input[train.index,])
train.label = as.matrix(fshdl_target[train.index,]$label)
test.data = as.matrix(fshdl_input[-train.index,])
test.label = as.matrix(fshdl_target[-train.index,]$label)

# Transform the two data sets into xgb.Matrix
xgb.train = xgb.DMatrix(data=train.data,label=train.label)
xgb.test = xgb.DMatrix(data=test.data,label=test.label)
```

```{r}
num_class = 2
params = list(
  booster="gbtree",
  eta=0.001,
  max_depth=5,
  gamma=3,
  subsample=0.75,
  colsample_bytree=1,
  objective="multi:softprob",
  eval_metric="mlogloss",
  num_class=num_class
)

xgb.fit=xgb.train(
  params=params,
  data=xgb.train,
  nrounds=10000,
  nthreads=1,
  early_stopping_rounds=10,
  watchlist=list(val1=xgb.train,val2=xgb.test),
  verbose=0
)

# TODO: importance matrix of predictors. do they match MEBN?

```

```{r}

#eval.mat <- matrix(0, nrow=nrow(assumedtargets),ncol=4)
eval.mat <- matrix(0, nrow=1,ncol=3)

i <- 1 
for (w in c(4,8,12))
{
  # Prediction accuracy for different weeks 
  week.index <- sysdimet$WEEK == w
  
  test.data = as.matrix(fshdl_input[week.index,])
  test.label = as.matrix(fshdl_target[week.index,]$label)
  xgb.test = xgb.DMatrix(data=test.data,label=test.label)
  
  xgb.pred = predict(xgb.fit,test.data,reshape=T)
  xgb.pred = as.data.frame(xgb.pred)
  colnames(xgb.pred) = c(0,1)
  
  # Use the predicted label with the highest probability
  xgb.pred$prediction = apply(xgb.pred,1,function(x) colnames(xgb.pred)[which.max(x)])
  xgb.pred$label = test.label

  # Calculate the final accuracy
  result = sum(as.integer(xgb.pred$prediction==xgb.pred$label))/nrow(xgb.pred)

  eval.mat[1,i] <- sprintf("%1.0f", 100*result)
  i <- i + 1
}

eval.mat
```
```{r}
# Review the final model and results
#xgb.fit

# Predict outcomes with the test data
xgb.pred = predict(xgb.fit,test.data,reshape=T)
xgb.pred = as.data.frame(xgb.pred)
colnames(xgb.pred) = c(0,1)

# Use the predicted label with the highest probability
xgb.pred$prediction = apply(xgb.pred,1,function(x) colnames(xgb.pred)[which.max(x)])
xgb.pred$label = test.label

# Calculate the final accuracy
result = sum(xgb.pred$prediction==xgb.pred$label)/nrow(xgb.pred)
print(paste("Final Accuracy =",sprintf("%1.2f%%", 100*result)))
```

```{r}
importance_matrix <- xgb.importance(model = xgb.fit)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)

```
