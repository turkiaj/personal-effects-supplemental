---
title: "Revealing Personal Effects of Nutrition with Mixed-Effect Bayesian Network"
subtitle: "Supplementary Materials"
author:
- Jari Turkia, jari.turkia@cgi.com
- School of Computing, University of Eastern Finland, Joensuu, Finland
bibliography: biblio.bib
output:
  pdf_document: default
  html_document: default
abstract: This notebook is supplementary material for the article "Revealing Personal Effects of Nutrition with Mixed-Effect Bayesian Network". The notebook shows in detail how mixed-effect Bayesian network is constructed and how it is used to model the effects of nutrition. The hierarchical structure of the network model allows studying the effects in both typical and personal levels. In addition, it is shown that the personal effects form clusters of similarly behaving subjects. Finally, personal networks are predicted for unseen subjects with cross-validation. This shows that there exist personal differences in nutrional effects, and they can be detected from repeated observations of food records and blood concentrations.
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra) # for HTML and Latex tables

knitr::opts_chunk$set(echo = TRUE, fig.align="center")

# this allows using tikz rendering for plots with "dev=tikz"
knit_hooks$set(plot = function(x, options) {
  if ('tikz' %in% options$dev && !options$external) {
    hook_plot_tex(x, options)
  } else hook_plot_md(x, options)
})

# Fix seed for random number generator for getting consistent results in kmeans etc.
fixed_seed <- 678

# Load common MEBN package
source("mebn/MEBN.r")

# Online version (TRUE) uses color images while (FALSE) renders exact figures for the article 
RenderArticleFigures <- FALSE
```

In this work we propose Bayesian network as an appealing way to model and predict the effects of nutrition. Bayesian networks are directed graphical models that describe a joint probability distribution where nodes of the graph are random variables and edges between the nodes form a conditional probability structure. In nutritional modeling we assign nutritional composition of subjects' diet and different blood concentrations as those random variables, and study the connections between them. The goal is then to find such connections for the graph that most probably describe the correct conditional relationships between nutrients and their effects.

# Motivating example of personal nutrition data

As an example, we analyze a dataset from the Sysdimet study [@pmid21901116] that contains four repeated measurements of 17 nutrients, some basic information about the subject (gender, medication) and their corresponding blood concentrations, from 106 individuals. 

```{r data_loading, echo=FALSE, message=FALSE}

# Read the data description
datadesc <- read.csv(file="data/SYSDIMET_data_description.csv", header = TRUE, sep = ";")

# Read the actual data matching the description
sysdimet <- read.csv(file="data/SYSDIMET_diet.csv", sep=";", dec=",")

# Define how to iterate through the graph
assumedpredictors <- datadesc[datadesc$Order==100,]    
assumedtargets <- datadesc[datadesc$Order==200,] 
```

Following spagettiplots show the progress of blood concentrations during the 12-week study. Measurements of only ten from 106 subjects are shown at the plots for clarity. Our goal is to predict next personal blood concentration when subject's diet from past weeks is known.

```{r spagettiplot_data, echo=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)
library(grid)

plot_patients_index <- seq(1, length(levels(sysdimet$SUBJECT_ID)), 5)
plot_patients <- levels(sysdimet$SUBJECT_ID)[plot_patients_index]

sysdimet_every_10th <- sysdimet[sysdimet$SUBJECT_ID %in% plot_patients,]
```

```{r spagettiplot_fshdl, eval = RenderArticleFigures, echo=FALSE, fig.align="left", fig.height=2, fig.width=5, message=FALSE}
# Fig. 1 in article

hdlplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fshdl, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_discrete(limits=c(0,4,8,12)) +
  labs(x = "Week", y = "HDL-chol. (mmol/l)") + theme(axis.title.x = element_blank()) +
  scale_colour_grey() +
  theme_bw()

hdlplot
```

```{r spagettiplot, echo=FALSE, fig.align="left", fig.height=7, fig.width=6, message=FALSE}
hdlplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fshdl, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_discrete(limits=c(0,4,8,12)) +
  labs(x = "Week", y = "HDL-chol. (mmol/l)") + theme(axis.title.x = element_blank())

ldlplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fsldl, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_discrete(limits=c(0,4,8,12)) +
  labs(x = "Week", y = "LDL-chol. (mmol/l)") + theme(axis.title.x = element_blank())

insplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fsins, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_discrete(limits=c(0,4,8,12)) +
  labs(x = "Week", y = "Insulin (mU/l)") + theme(axis.title.x = element_blank())

kolplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fskol, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_discrete(limits=c(0,4,8,12)) +
  labs(x = "Week", y = "Total chol. (mmol/l)") + theme(axis.title.x = element_blank())

glukplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fpgluk, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_discrete(limits=c(0,4,8,12)) +
  labs(x = "Week", y = "Glucose (mmol/l)") 

grid.arrange(hdlplot, ldlplot, kolplot, insplot, glukplot, nrow = 5, ncol=1, padding=0) 

```

When the future direction of the blood concetrations can be predicted, the typical and personal importance of nutrients contributing this change be estimated from the model parameters. 

# Mixed-effect Bayesian network

We focus only on two-level, bipartite, graphs where nutrients and personal details are assumed to affect blood concentrations, and only the magnitude of the effect is left to be estimated. 

```{r graph, fig.height = 5, fig.align = "left", echo=FALSE, message=FALSE}
library(igraph)
initial_graph <- mebn.fully_connected_bipartite_graph(datadesc)

V(initial_graph)$size = 10 

# - put all blood concentrations in own rank
bipa_layout <- layout_as_bipartite(initial_graph, types = V(initial_graph)$type == "100")
# - flip layout sideways, from left to right
gap <- 6
bipa_layout <- cbind(bipa_layout[,2]*gap, bipa_layout[,1])

V(initial_graph)[V(initial_graph)$type == "100"]$label.degree = pi # left side
V(initial_graph)[V(initial_graph)$type == "200"]$label.degree = 0 # right side

plot(initial_graph,
       layout=bipa_layout, 
       rescale=TRUE,
       vertex.label.color="black",
       vertex.label.cex=0.7,
       vertex.label.dist=3.8,
       edge.arrow.size=0.5,
       edge.arrow.width=1,
       axes=FALSE,
       margin=0,
       layout.par = par(mar=c(0,0,0,0)))

```

We assume a connection from every nutrient and personal information to every blood concentration value at the dataset. The model search is then focused on to estimating optimal coefficients describing the connections. 

# Model development

Our starting assumption is that both nutrients and the blood concentrations are normally distributed. This assumption may be naive as it allows the blood concentrations to have negative values. We normalize all the input values to same scale, so that the estimated regression coefficients can be used as a indicators of connection strenght.

```{r graph_with_normal_rvs, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
sysdimet_normal <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                         inputdata = sysdimet,
                                         predictor_columns = assumedpredictors, 
                                         assumed_targets = assumedtargets, 
                                         group_column = "SUBJECT_ID",
                                         local_estimation = mebn.sampling,
                                         local_model_cache = "models/BLMM_normal", 
                                         stan_model_file = "mebn/BLMM_normal.stan",
                                         normalize_values = TRUE)

write.graph(sysdimet_normal, "graphs/sysdimet_normal.graphml", "graphml")

```

Here we evaluate the fit of model candidates visually by plotting the posterior predictive distributions (PPC) over the distributions of the true blood concenrations. As expected, normal distribution in random variables is not fitting well. Normal distribution allows non-zero probability for negative blood concenrations resulting the probability to leak for impossible values. Normal distribution is also symmetric while the distributions of blood concenrations are usually more skewed to right. 

```{r normal_model_ppc, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
mebn.target_dens_overlays("BLMM_normal/", assumedtargets, sysdimet)
```


## Developing the model beyond normal distributions

More realistic probability distribution for blood concenrations would be Log-Normal or Gamma distributions [@10.1371/journal.pone.0021403]. They both allow only positive values and model better the right tail of individual larger values. For further development, we choose Gamma distribution with identity link function. This is important as it keeps the regression coefficients of the nutrients on the same absolute scale than with Normal models. The regression coefficients are used as weights of the edges at the Bayesian network and they all should be on the same scale regardless of the random variables' distribution. 

```{r graph_with_gamma_response, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
initial_gamma_graph <- mebn.new_graph_with_randomvariables(datadesc)

sysdimet_gamma <- mebn.bipartite_model(reaction_graph = initial_gamma_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma", 
                                   stan_model_file = "mebn/BLMM_gamma.stan",
                                   normalize_values = TRUE)

write.graph(sysdimet_gamma, "graphs/sysdimet_gamma.graphml", "graphml")
```

The visual comparison of the true and estimated distributions of blood concenrations shows that Gamma distribution follows the true distributions quite well. 

```{r gamma_ppc, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
mebn.target_dens_overlays("BLMM_gamma/", assumedtargets, sysdimet)
```

The visual PPC inspection shows that the Gamma distribution fit generally better to responses than Normal distribution, but cholesterol concentrations are still systematically estimated too low (fsldl and fskol) or too high (fshdl).

## Modeling correlated observations with an autocorrelation process

In the dataset the observations from subjects' food records and blood concentrations have one week response time. This might not be optimal time for all the responses and the successive observations might be correlated. For modeling the correlated observations, we add an autocorrelation process to the model by adding an estimated portion of previous measurement to the linear predictor

```
mu[n] += Y[n-1] * ar1
```      

This coefficient 'ar1' is estimated separately for each response

```{r graph_with_gamma_ar1, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_gamma_ar1 <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma/ar1", 
                                   stan_model_file = "mebn/BLMM_gamma_ar1.stan",
                                   normalize_values = TRUE)

mebn.write_gexf(sysdimet_gamma_ar1, "graphs/sysdimet_gamma_ar1.gexf")
write_graph(sysdimet_gamma_ar1, "graphs/sysdimet_gamma_ar1.graphml", "graphml")

```

The autocorrelation structure seems to decrease the variance of the model and correcting the systematical estimation errors from the previous model candidate

```{r gamma_ar1_ppc, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1/", assumedtargets, sysdimet)
```


It is interesting also to compare the AR(1) coefficients of different local distributions at the graph. Blood insulin (fsins) has largest AR(1) coefficient indicating that successive measurements are most correlated and the values are not changing as rapidly as with other measurements. Credible interval for cholesterol measurements includes zero indicating that autocorrelation is very low or non-existent between two measurements.

```{r ar1_comparison, message=FALSE, warning=FALSE, cache=TRUE}
ar1_comparison <- mebn.AR_comparison(assumedtargets, "BLMM_gamma/ar1")
```
```{r ar1_comparison_table, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.height=5}
kable(ar1_comparison) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)
```

## Skrinkage prior model

In our analysis, we use two models: 1) typical effects are better shown with previous model that has vague prior on beta coefficients, and 2) personal effects became clearer in a model that uses shrinkage prior on beta coefficients. This shrinkaged model is also faster to evaluate in k-fold setting and is possibly a better predictor.

The predictive ability of the model might be reduced if the model overfits to small nuances of the dataset. To overcome the possible overfitting, we apply a shrinkage prior "Regularized Horseshoe Shrinkage (RHS)", also called Finnish horseshoe, on regression coefficients. It allows specifying a prior knowledge, or at least an educated guess, about the number of significant predictors for a target. Here we assume that one third of the nutrients might be relevant for any given blood concenration, and apply following parameters for the shrinkage

```{r shrinkage_parameters, echo=TRUE, message=FALSE}
shrinkage_parameters <- within(list(),
{
    scale_icept  <- 1         # prior std for the intercept
    scale_global <- 0.02266   # scale for the half-t prior for tau: 
                              # ((p0=7) / (D=22-7)) * (sigma = 1 / sqrt(n=106*4))
    nu_global    <- 1         # degrees of freedom for the half-t priors for tau
    nu_local     <- 1         # degrees of freedom for the half-t priors for lambdas
    slab_scale   <- 1         # slab scale for the regularized horseshoe
    slab_df      <- 1         # slab degrees of freedom for the regularized horseshoe           
})
```

Next we fit the previous model with the Finnish horseshoe added. Besides the shrinkage parameters, we provide now the data in two sets: input data for estimation and target data to hold out for prediction. 

```{r noholdout_index}
# One RHS model with all data (no_holdout)
holdout_index <- rep(0, nrow(sysdimet))
```

```{r BLMM_gamma_ar1_rhs_cv_ppc, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_gamma_ar1_rhs_pred <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   targetdata = holdout_index,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = paste0("models/BLMM_gamma/ar1_rhs/no_holdout"), 
                                   stan_model_file = "mebn/BLMM_gamma_ar1_rhs_cv_ppc.stan",
                                   reg_params = shrinkage_parameters,
                                   normalize_values = TRUE)


write.graph(sysdimet_gamma_ar1_rhs_pred, "graphs/sysdimet_gamma_ar1_rhs.graphml", "graphml")
```

```{r gamma_ar1_rhs_ppc, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1_rhs/no_holdout/", assumedtargets, sysdimet)
```

Visual comparison with posterior predictive check seem to favor this model. Let us confirm the evaluation with numerical metrics.

# Evaluation of the models' fit and predictive performance

Different model versions are compared with a normalized root mean squared error (NRMSE) and also with a classification test that allows comparison with other classification methods.

## Comparison with in-sample data

Following compares different model candidates by using normalized root mean squared error (NRMSE) metrics. Normalization allows comparing the prediction accuracy of responses with different scales.

```{r NRMSE comparison, eval=FALSE, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
source("model_eval_functions.r")

allrep_normal <- get_rep_response_for_all("models/BLMM_normal/")
allrep_gamma <- get_rep_response_for_all("models/BLMM_gamma/")
allrep_rhs <- get_rep_response_for_all("models/BLMM_gamma/ar1_rhs/no_holdout/")
allrep_norhs <- get_rep_response_for_all("models/BLMM_gamma/ar1/")

# Normal distribution model
nrmse.mat <- matrix(0, nrow=0,ncol=7)
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_normal, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- sqrt((rep_response - true_response)^2)
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Normal", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

# Gamma distribution model without autocorrelation

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_gamma, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Gamma", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

# Gamma model with AR(1) structure

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_norhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Gamma AR(1)", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

# Gamma model with AR(1) structure and RHS prior on betas

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_rhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Gamma AR(1) RHS", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

colnames(nrmse.mat)[1] <- "model"
colnames(nrmse.mat)[7] <- "mean"

saveRDS(nrmse.mat, "evaluations/NRMSE-matrix1.rds")
```

```{r model_nrmse1, echo=FALSE, message=FALSE, warning=FALSE}
nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix1.rds")

#kable(nrmse.mat) %>%
#  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
#  row_spec(0,bold=TRUE)

kable(nrmse.mat, "latex", booktabs = T, caption = "Predictive accuracy percents for correct direction of change") %>%
  kable_styling(latex_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)

```

The comparson shows that Gamma distribution with AR(1) autocorralation structure has best overall fit to data. The horseshoe prior on typical effects has shrinked some coefficients close to zero and it has increased mean NRMSE just a little. An interesting finding is that the blood insulin (fsins) predictions are better modeled with Normal distribution. For the final MEBN we replace Gamma AR(1) with Normal AR(1) model for fsins.

```{r graph_with_normal_ar1, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}

# We can fit local distribution for fsins separately by defining a Bayesian network with just this one response node. 
# In following chunks, we fit both non-shrinked and regularized horseshoe-shrinked versions of Normal AR(1) model.

initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
only_fsins <- assumedtargets[assumedtargets$Name=="fsins",]

fsins_normal_ar1 <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = only_fsins, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_normal/ar1", 
                                   stan_model_file = "mebn/BLMM_normal_ar1.stan",
                                   normalize_values = TRUE)

```

```{r graph_with_normal_ar1_rhs, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# One RHS model with all data (no_holdout)
holdout_index <- rep(0, nrow(sysdimet))
```
```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
only_fsins <- assumedtargets[assumedtargets$Name=="fsins",]

fsins_normal_ar1_rhs <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   targetdata = holdout_index,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = only_fsins, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = paste0("models/BLMM_normal/ar1_rhs/no_holdout"), 
                                   stan_model_file = "mebn/BLMM_normal_ar1_rhs_cv_ppc.stan",
                                   reg_params = shrinkage_parameters,
                                   normalize_values = TRUE)

``` 

Plot on the left is a PPC of Gamma distributed fsins-response and the right plot is a normally distributed response that fits better with lower mean squared error

```{r fsins_comparison, fig.width=6, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
library(gridExtra)

only_fsins <- assumedtargets[assumedtargets$Name=="fsins",]
gamma_plot <- mebn.target_dens_overlays("BLMM_gamma/ar1_rhs/no_holdout/", only_fsins, sysdimet)
normal_plot <- mebn.target_dens_overlays("BLMM_normal/ar1_rhs/no_holdout/", only_fsins, sysdimet)

grid.arrange(gamma_plot, normal_plot,  nrow = 1, widths=c(2,2), padding=0)
```

Next, we contruct a EXPFAM AR(1) model that has this normally distributed fsins-response and otherwise Gamma distributed blood concenration responses.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Other local distributions use Gamma AR1 model, but fsins uses Normal AR1
expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

expfam_ar1_rhs_dirs <- assumedtargets
expfam_ar1_rhs_dirs$modelcache <- "models/BLMM_gamma/ar1_rhs/no_holdout"
expfam_ar1_rhs_dirs[expfam_ar1_rhs_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1_rhs/no_holdout"
```

```{r nrmse_expfam, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
source("model_eval_functions.r")
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))
nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix1.rds")

## EXPFAM AR(1)

allrep_expfam_ar1 <- get_rep_response_for_expfam(expfam_ar1_dirs)

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_expfam_ar1, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("EXPFAM AR(1)", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

## EXPFAM AR(1) RHS

allrep_expfam_ar1_rhs <- get_rep_response_for_expfam(expfam_ar1_rhs_dirs)

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_expfam_ar1_rhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("EXPFAM AR(1) RHS", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

saveRDS(nrmse.mat, "evaluations/NRMSE-matrix2.rds")
```

```{r expfam_ar1_model, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_expfam_ar1 <- mebn.bipartite_expfam_bn(initial_graph, assumedpredictors, assumedtargets, expfam_ar1_dirs)

write.graph(sysdimet_expfam_ar1, "graphs/sysdimet_expfam_ar1.graphml", "graphml")
```

```{r expfam_ar1_rhs_model, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_expfam_ar1_rhs <- mebn.bipartite_expfam_bn(initial_graph, assumedpredictors, assumedtargets, expfam_ar1_rhs_dirs)

write.graph(sysdimet_expfam_ar1_rhs, "graphs/sysdimet_expfam_ar1_rhs.graphml", "graphml")
```

## Predictive accuracy cross-validated MEBN 

Execution of the k-fold cross-validation is done in a separated notebook (cross-validation.Rmd) as it takes substantial amount of time to run. The results are stored and load for analysis here. For the cross-validation we partitioned the observations in data to 12 partitions for weeks 4,8 and 12. Then each of the data partitions in turn is left out from model estimation. This allows us to make predictions for unseen data. 

Each of the model candidates are compared here with a normalized root mean squared error (NRMSE) and last final versions (Gamma AR(1) RHS CV and Expfam AR(1) RHS CV) are evaluated with the cross-validation.

```{r model_mse3, echo=FALSE}
# Cross-validation.Rmd adds CV evaluations to NRMSE-matrix3.rds
```

```{r model_nrmse2, echo=FALSE, message=FALSE, warning=FALSE}
nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix3.rds")

#kable(nrmse.mat) %>%
#  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
#  row_spec(0,bold=TRUE)

kable(nrmse.mat, "latex", booktabs = T, caption = "NRMSE comparison between model candidates") %>%
  kable_styling(latex_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)

```

```{r nrmse_plot_vertical, fig.height = 3, fig.width = 5, echo=FALSE, fig.align = "left", message=FALSE, warning=FALSE, cache=TRUE}
library(ggplot2)

nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix3.rds")
nrmse.df <- data.frame(nrmse.mat[,1])

# model is a string factors, NRMSEs are doubles
nrmse.df$model <- factor(nrmse.mat[,1], levels = rev(c("Normal","Gamma","Gamma AR(1)","Gamma AR(1) RHS","EXPFAM AR(1)","EXPFAM AR(1) RHS", "Gamma AR(1) RHS CV", "EXPFAM AR(1) RHS CV")))
nrmse.df <- cbind(nrmse.df, apply(nrmse.mat[,2:7], 2, as.numeric))[,2:8]

#label.df <- as.data.frame(paste0(colnames(nrmse.mat)[2:7], " ", sprintf(as.numeric(nrmse.mat[6,2:7]), fmt = '%#.3f')))
#label.df <- as.data.frame(colnames(nrmse.mat)[2:7])
label.df <- as.data.frame(c("cholesterol","","fsins","","fpgluk","mean"))
label.df <- cbind(label.df, as.numeric(nrmse.mat[7,2:7]))
colnames(label.df) <- c("label", "value")

ggplot(nrmse.df, show.legend = FALSE) +
  geom_line(aes(y = fshdl, x = model, group=1), size=0.3) +
  geom_line(aes(y = fsldl, x = model, group=1), size=0.3) +
  geom_line(aes(y = fsins, x = model, group=1), size=0.3) +
  geom_line(aes(y = fskol, x = model, group=1), size=0.3) +
  geom_line(aes(y = fpgluk, x = model, group=1), size=0.3) +
  geom_line(aes(y = mean, x = model, group=1), size=1) +
  geom_text(data = label.df, aes(label = label, x = "EXPFAM AR(1) RHS CV", y = value, hjust = .2, vjust = (label == "fpgluk")*1.0+1.0), size = 3) +
  scale_y_continuous() +
  labs(x = "", y = "NRMSE") + 
  coord_flip() +
  theme_bw() +
  theme(axis.text.x=element_text(size=rel(0.9)), plot.margin = margin(0,3,0,0)) 

```


# Evaluation with classification metrics

Normalized root mean squared error (NRMSE) is good for comparing model candidates, but it does not say much about the actual usefulness of the model. For personal nutrition guiding, it is important to predict how given diet will affect the future blood concenration values. In the standard NRMSE comparison, the error between true and predicted values were compared, but a custom classification test can be also used. It tells if the given diet raises or lowers the future blood concenrations compared to past measurement. 

Classification test allows also to compare MEBN with other classification methods. XGBoost is a well-performing decision tree method. It is a non-parametric machine learning method that learns personal reactions only by example. Following compares the cross-validated predictive accuracy of XGBoost with MEBN predictions (MEBN CV) that uses EXPFAM AR(1) RHS-model. Also in-sample MEBN fit with non-shrinked EXPFAM AR(1) is given for comparison. This best predicting model is used for dataset analysis at rest of this notebook.      

```{r expfam_ar1_accuracy, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
source("model_eval_functions.r")

# Summary matrix for AR(1) NON-RHS model with in-sample data

class.mat <- matrix(0, nrow=nrow(assumedtargets),ncol=3)
rownames(class.mat) <- assumedtargets$Name
colnames(class.mat) <- c('week 4', 'week 8', 'week 12')

allrep_expfam_ar1 <- get_rep_response_for_expfam(expfam_ar1_dirs)

number_of_preds <- 0
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))

for (subject_number in 1:amount_subjects)
{
  number_of_preds <- number_of_preds + 1
  
  rep_response <- get_rep_response(allrep_expfam_ar1, subject_number)
  true_response <- get_true_response(subject_number)
  
  rep_delta <- make_delta(true_response, rep_response)
  true_delta <- make_delta(true_response, true_response)
  
  sign_matrix <- sign(rep_delta) == sign(true_delta)
  sign_matrix[,2:4]*1

  class.mat <- class.mat + sign_matrix[,2:4]*1
}

class_sum.mat <- class.mat/number_of_preds * 100

class_sum.mat <- cbind(class_sum.mat, rowMeans(class_sum.mat[,1:3]))
colnames(class_sum.mat) <- c('0 to 4 weeks', '4 to 8 weeks', '8 to 12 weeks', 'mean accuracy')

#percent.mat <- rbind(percent.mat, percent_nonrhs.mat)
class_sum.mat <- round(class_sum.mat, 0)
saveRDS(class_sum.mat, "evaluations/Class-matrix1.rds")
```

```{r expfam_ar1_rhs_accuracy, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
source("model_eval_functions.r")

# Summary matrix for RHS model with in-sample data

class.mat <- matrix(0, nrow=nrow(assumedtargets),ncol=3)
rownames(class.mat) <- assumedtargets$Name
colnames(class.mat) <- c('week 4', 'week 8', 'week 12')

allrep_expfam_ar1_rhs <- get_rep_response_for_expfam(expfam_ar1_rhs_dirs)

number_of_preds <- 0
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))

for (subject_number in 1:amount_subjects)
{
  number_of_preds <- number_of_preds + 1
  
  rep_response <- get_rep_response(allrep_expfam_ar1_rhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  rep_delta <- make_delta(true_response, rep_response)
  true_delta <- make_delta(true_response, true_response)
  
  sign_matrix <- sign(rep_delta) == sign(true_delta)
  class.mat <- class.mat + sign_matrix[,2:4]*1
}

class_sum.mat <- class.mat/number_of_preds * 100

class_sum.mat <- cbind(class_sum.mat, rowMeans(class_sum.mat[,1:3]))
colnames(class_sum.mat) <- c('0 to 4 weeks', '4 to 8 weeks', '8 to 12 weeks', 'mean accuracy')

#percent.mat <- rbind(percent.mat, percent_nonrhs.mat)
class_sum.mat <- round(class_sum.mat, 0)
saveRDS(class_sum.mat, "evaluations/Class-expfam_rhs_matrix.rds")
```

## Summary of the model comparison

This table summarizes how accurately we can predict if blood concenration increase or decrease when the current level and a diet are known. This evaluates the model that uses shrinkage. 

```{r accuracy_plot, echo=FALSE, fig.align="left", fig.height=3, fig.width=5, message=FALSE}
library(ggplot2)
library(gridExtra)
library(grid)

class_sum.mat <- readRDS("evaluations/Class-matrix1.rds")

# Pick only 4 weeks average for comparison from MEBN
class.df <- as.data.frame(as.vector(class_sum.mat[,4]))
class.df$model <- "MEBN"

#labs <- c("4 weeks", "12 weeks")
#class.df$labels <- factor(labs[rep(1, each=5)], levels = labs)

colnames(class.df) <- c("accuracy", "method")

# MEBN RHS
mebn_rhs.mat <- readRDS("evaluations/Class-expfam_rhs_matrix.rds")
mebn_rhs.df <- as.data.frame(mebn_rhs.mat[,4]-2)
mebn_rhs.df$method <- "MEBN RHS"
colnames(mebn_rhs.df) <- c("accuracy","method")
class.df <- rbind(class.df, mebn_rhs.df)

# Add MEBN CV for comparison

# Cross-validation of non-shrinked model is omitted from final figure as it performs worst, as expected.

#mebn_cv.mat <- readRDS("evaluations/ExpfamNonRHS_CV_accuracy_matrix.rds")
#mebn_cv.df <- as.data.frame(mebn_cv.mat[,4]-2)
#mebn_cv.df$method <- "MEBN CV"
#colnames(mebn_cv.df) <- c("accuracy","method")
#class.df <- rbind(class.df, mebn_cv.df)

# Add MEBN RHS CV for comparison
mebn_rhs_cv.mat <- readRDS("evaluations/GammaCV_accuracy_matrix.rds")
mebn_rhs_cv.df <- as.data.frame(mebn_rhs_cv.mat[,4]-2)
mebn_rhs_cv.df$method <- "MEBN RHS CV"
colnames(mebn_rhs_cv.df) <- c("accuracy","method")
class.df <- rbind(class.df, mebn_rhs_cv.df)

# Add XGBoost for comparison
xgboost.mat <- readRDS("evaluations/xgboost-cv-mat.rds")
xgboost.df <- as.data.frame(round(as.numeric(xgboost.mat[,2])*100, 0))
xgboost.df$method <- "XGBoost CV"
colnames(xgboost.df) <- c("accuracy","method")
class.df <- rbind(class.df, xgboost.df)

# Add response column for all methods
class.df$response <- rep(rownames(class_sum.mat), 4)

ggplot() +
  geom_col(data = class.df, aes(x=response, y=accuracy, fill=method), position = "dodge") +
  scale_y_discrete(limits=seq(0,100,10), labels = paste0(seq(0,100,10), "%")) +
  labs(x = "Blood concentration", y = "Prediction accuracy") + theme(axis.title.x = element_blank()) +
  scale_fill_grey(start = .3, end = .7) + theme_bw()

```

```{r model_summary, echo=FALSE, message=FALSE, warning=FALSE}

# Load in-sample MEBN first
class_sum.mat <- readRDS(file="evaluations/GammaCV_accuracy_matrix.rds")

# Add XGBoost
#class_sum.mat <- rbind(class_sum.mat, xgboost.mat)

class_sum.mat[,1:4] <- paste0(class_sum.mat[,1:4], "%")

#kable(class_sum.mat, caption = "Predictive accuracy percents for correct direction of change") %>%
#  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
#  row_spec(0,bold=TRUE)

kable(class_sum.mat, "latex", booktabs = T, caption = "Predictive accuracy percents for correct direction of change") %>%
  kable_styling(latex_options = c("striped", "condensed"), full_width = TRUE) %>%
 row_spec(0,bold=TRUE)

```


# Typical effects of nutrition and personal variance

We have now reached a reasonably good fit for the local distributions of the Bayesian network. Our code has extracted a graphical model from these  posterior distributions of random variables and parameters. The graph consists mean values of the posteriors and also their credible intervals. This is a lighter data structure for further analysis and allows also graph operations besides the regression modeling.

Besides the random variables, the graph also includes the regression coefficients $\beta$ and $b$ that denote the typical and personal magnitudes of the effects for different nutrients. For better overview, let us plot the graph of typical nutritional effects. This visualization shows mean of posterior for typical coefficients $\beta$ as weight of the connection between blood concentrations and nutrients at diet affecting it. For clarity, the visualization only shows 15 principal components explaining the variance of each blood concentrationś

```{r, typical_effects_figure, fig.height = 4, fig.width=5, echo=FALSE, fig.align = "left", message=FALSE, warning=FALSE, cache=FALSE}
source("mebn/MEBN.r")
require(igraph)
sysdimet_expfam_ar1 <- read_graph("graphs/sysdimet_expfam_ar1.graphml", "graphml")

graph_layout <- mebn.plot_typical_effects(sysdimet_expfam_ar1, 20, graph_layout = NULL, colorImage = !RenderArticleFigures)
```

```{r typical_nonshrinked, echo=FALSE, message=FALSE, eval=TRUE}
library(igraph)
library(dplyr)
sysdimet_expfam_ar1 <- read_graph("graphs/sysdimet_expfam_ar1.graphml", "graphml")

# Query the graph for typical strengths of the effects
allnodes <- V(sysdimet_expfam_ar1)
beta <- allnodes[allnodes$type=="beta"]
b_sigma <- allnodes[allnodes$type=="b_sigma"]

# Again, a separate data frame is constructed for printing
typical_effects<-data.frame(matrix(NA, nrow=length(beta), ncol=0))

# HTML
typical_effects$effect_text <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

# Latex
typical_effects$effect <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

typical_effects$effect <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0("$\\text{", toString(datadesc[datadesc$Name==x[1],]$Description),"}$ $\\rightarrow$ $\\text{", toString(datadesc[datadesc$Name==x[2],]$Description), "}$")))

typical_effects$target <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) toString(datadesc[datadesc$Name==x[2],]$Description)))

typical_effects$strength <- round(beta$value, digits = 2)
typical_effects$effect_CI <- paste0("$\\text{[",round(beta$value_lCI, digits = 2),";", round(beta$value_uCI, digits = 2),"]}$")
typical_effects$effect_lCI <- beta$value_lCI
typical_effects$effect_uCI <- beta$value_uCI

typical_effects$variance <- round(b_sigma$value, digits = 2) 
typical_effects$variance_CI <- paste0("$\\text{[",round(b_sigma$value_lCI, digits = 2),";", round(b_sigma$value_uCI, digits = 2),"]}$")
typical_effects$variance_lCI <- b_sigma$value_lCI
typical_effects$variance_uCI <- b_sigma$value_uCI

ordered_typical_effects <- typical_effects %>%
  group_by(target) %>%
  filter(abs(strength) > 0.3 | variance > 0.3) %>%
  ungroup(target) %>%
  select(-target)

row.names(ordered_typical_effects) <- NULL
```

```{r typical_shrinked, echo=FALSE, message=FALSE, eval=TRUE}
library(igraph)
library(dplyr)
sysdimet_expfam_ar1_rhs <- read_graph("graphs/sysdimet_expfam_ar1_rhs.graphml", "graphml")

# Query the graph for typical strengths of the effects
allnodes <- V(sysdimet_expfam_ar1_rhs)
beta <- allnodes[allnodes$type=="beta"]
b_sigma <- allnodes[allnodes$type=="b_sigma"]

# Again, a separate data frame is constructed for printing
typical_effects_rhs<-data.frame(matrix(NA, nrow=length(beta), ncol=0))

# HTML
typical_effects_rhs$effect_text <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

# Latex
typical_effects_rhs$effect <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0("$\\text{", toString(datadesc[datadesc$Name==x[1],]$Description),"}$ $\\rightarrow$ $\\text{", toString(datadesc[datadesc$Name==x[2],]$Description), "}$")))

typical_effects_rhs$target <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) toString(datadesc[datadesc$Name==x[2],]$Description)))

typical_effects_rhs$strength <- round(beta$value, digits = 2)
typical_effects_rhs$effect_CI <- paste0("$\\text{[",round(beta$value_lCI, digits = 2),";", round(beta$value_uCI, digits = 2),"]}$")
typical_effects_rhs$effect_lCI <- beta$value_lCI
typical_effects_rhs$effect_uCI <- beta$value_uCI

typical_effects_rhs$variance <- round(b_sigma$value, digits = 2) 
typical_effects_rhs$variance_CI <- paste0("$\\text{[",round(b_sigma$value_lCI, digits = 2),";", round(b_sigma$value_uCI, digits = 2),"]}$")
typical_effects_rhs$variance_lCI <- b_sigma$value_lCI
typical_effects_rhs$variance_uCI <- b_sigma$value_uCI

# Note: we take the same effects than non-shrinked model

ordered_typical_effects_rhs <- typical_effects_rhs %>%
  group_by(target) %>%
  filter(effect %in% ordered_typical_effects$effect) %>%
  ungroup(target) %>%
  select(-target)

row.names(ordered_typical_effects_rhs) <- NULL

# Sort by this column
ordered_typical_effects_rhs$nonrhs_variance <- ordered_typical_effects$variance 

```

We can examine closer the effects in the previous graph. In following, we show 90% credible interval for each effect and sort them by variance between persons. These effects with high variance between persons are intresting to us.

```{r high_varying_effects,  fig.height = 5, fig.width = 6.5, fig.align="left", echo=FALSE, message=FALSE, warning=FALSE}

library(ggplot2)
library(gridExtra)

# Arrange both similarly
ordered_typical_effects <- ordered_typical_effects %>% arrange(variance)
ordered_typical_effects_rhs <- ordered_typical_effects_rhs %>% arrange(nonrhs_variance)

ordered_typical_effects$lowers_rises <- ifelse(ordered_typical_effects$strength < 0, "lowers", "raises")
ordered_typical_effects_rhs$lowers_rises <- ifelse(ordered_typical_effects_rhs$strength < 0, "lowers", "raises")

# Plot for typical effects

p1 <- ggplot(ordered_typical_effects, aes(x=effect_text, y=strength)) + 
  geom_bar(stat="identity", color="black", aes(fill=lowers_rises), 
           position=position_dodge(), show.legend = FALSE) +
  geom_errorbar(aes(ymin=effect_lCI, ymax=effect_uCI), width=.2,
                 position=position_dodge(.9)) +
  scale_x_discrete(limits=ordered_typical_effects$effect_text) +
  scale_fill_manual(values = c("#DDDDDD", "#888888")) +
  theme_bw() +
  theme(axis.title.y=element_blank(), 
        axis.text.y=element_text(size=9),
        axis.title.x=element_text(size=9)) +
  labs(y="non-shrinked strength") +
  coord_flip()

# Plot for shrinked typical effects

p2 <- ggplot(ordered_typical_effects_rhs, aes(x=effect_text, y=strength)) + 
  geom_bar(stat="identity", color="black", aes(fill=lowers_rises), 
           position=position_dodge(), show.legend = FALSE) +
  geom_errorbar(aes(ymin=effect_lCI, ymax=effect_uCI), width=.2,
                 position=position_dodge(.9)) +
  scale_x_discrete(limits=ordered_typical_effects_rhs$effect_text) +
  scale_fill_manual(values = c("#DDDDDD", "#888888")) +
  theme_bw() +
  theme(axis.title.y=element_blank(), 
        axis.text.y=element_blank(),
        axis.title.x=element_text(size=9)) +
  labs(y="shrinked strength") +
  coord_flip()


# Plot for between group effect variance

p3 <- ggplot(ordered_typical_effects, aes(x=effect_text, y=variance)) + 
  geom_point(shape=21, size=3, fill="white", stat="identity") +
  geom_errorbar(aes(ymin=variance_lCI, ymax=variance_uCI), width=.2,
                 position=position_dodge(.9)) +
  scale_x_discrete(limits=ordered_typical_effects$effect_text) +
  theme_bw() +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.title.x=element_text(size=9)) +
  labs(y="variance between patients") +
  coord_flip()  

grid.arrange(p1, p2, p3, nrow = 1, widths=c(4,2,2), padding=0)

```

These are the effect with most difference between subjects. Let us the examine closer those of the effects that have most probable variance over 0.30 and plot them as a graph

```{r personal_variations_figure, fig.height = 5, fig.align = "left", cache = FALSE}
source("mebn/MEBN.r")
effects_with_most_variance <- ordered_typical_effects[ordered_typical_effects$variance >= 0.30,]
effects_with_most_variance$effect <- effects_with_most_variance$effect_text
number_of_varying_effects <- nrow(effects_with_most_variance)

mebn.plot_personal_variations(sysdimet_expfam_ar1, number_of_varying_effects)
```

# Finding the clusters of personal reaction types

Although there are personal differences, it is likely that everyone is not behaving uniquely but there might exist similar groups of behavior. We can analyze personal differences in two ways. We can look the absolute magnitudes of effects and we can also look how persons differ from typical behavior or mean of the effect.

We can now take the personal estimations of the effects and see, if they form clusters

```{r kmeans_dfs, echo=FALSE, cache=FALSE, message=FALSE}
library(rstan)

# Pick these predictors as features for clustering -- get all
feature_index <- c(1:nrow(assumedpredictors))

personal_variations_from_mean <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))
personal_effects <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))

# Use non-shrinked model for clusters, so that they match to typical effects

expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

#modelcache <- "BLMM_gamma/ar1/"

# We could fetch a personal graph for all patients, but it is more effective to extract estimations directly from MCMC-samples to data frames

for (i in c(1:nrow(assumedtargets)))
{
  targetname <- as.vector(assumedtargets[i,]$Name)
  
  modelcache <- expfam_ar1_dirs[expfam_ar1_dirs==targetname,]$modelcache
  
  target_blmm <- mebn.get_localfit(targetname, modelcache)
  posterior <- rstan::extract(target_blmm, pars = c("personal_effect", "b"))

  b_blmm <- colMeans(posterior$b)
  beta_b_blmm <- colMeans(posterior$personal_effect)
  
  # Omit predictor columns here, if needed
  # - b has intercept as first column, so the index needs to be adjusted
  b_blmm <- b_blmm[,feature_index+1] 
  beta_b_blmm <- beta_b_blmm[,feature_index] 
  
  if (i == 1) {
    # variance of the intercept is omitted
    personal_variations_from_mean <- b_blmm
    personal_effects <- beta_b_blmm
  }
  else
  {
    personal_variations_from_mean <- cbind(personal_variations_from_mean, b_blmm)
    personal_effects <- cbind(personal_effects, beta_b_blmm)
  }
}

```

```{r, echo=FALSE, eval=TRUE, fig.height=3}
library(stats)
library(gridExtra)

set.seed(fixed_seed)
k.max <- 8
wss_effects <- sapply(1:k.max, function(k){kmeans(personal_effects, k, nstart=50, iter.max = 15)$tot.withinss})
wss_vars <- sapply(1:k.max, function(k){kmeans(personal_variations_from_mean, k, nstart=50, iter.max = 15)$tot.withinss})

df_vars <- data.frame(x = 1:k.max, y = wss_vars)
df_effects <- data.frame(x = 1:k.max, y = wss_effects)

plot1 <- ggplot(data=df_effects, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference in absolute reaction") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

plot2 <- ggplot(data=df_vars, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference from typical behavior") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

gridExtra::grid.arrange(plot1,plot2,nrow=1)
```

By looking previous diagram we see that there are four clearly identifiable groups between subjects, 

**The effect of cholesterol medication**

At this plot, zero of X-axis denotes a typical behaviour of that particular reaction, and bars denote a deviation from this typical mean.

```{r variation clusters1, echo=FALSE, eval=TRUE, fig.width=4, fig.height=5, cache=TRUE}
source("mebn/MEBN.r")

# Number of cluster centers 
k <- 4

# Clustering using k-means
set.seed(fixed_seed)
km <- kmeans(personal_variations_from_mean, centers = k)

# Every patient can be assigned to some cluster based on how their reactions differ from average
sysdimet$variation_group <- km$cluster 

# Plot the clusters
variations_data <- as.data.frame(t(km$centers))
cluster_index <- seq(1:k)
cluster_spread <- as.data.frame(table(km$cluster), stringsAsFactors = FALSE)
mebn.plot_clusters(variations_data, cluster_spread, cluster_index, assumedpredictors, assumedtargets, effects_with_most_variance, feature_index, sort_by_amount = TRUE)
```

Cholesterol medication seems to dominate the clusters. There are subjects for who cholesterol medication raises the blood insulin levels more than on average and for other group the raise is less than on average.

Let's see how the clustering shows with absolute effects rather than difference from mean. Note that these are not the greatest effects, but those with most personal variance.

```{r personal_effect_clusters_all, echo=FALSE, eval=TRUE, fig.width=4, fig.height=5, cache=TRUE}
source("mebn/MEBN.r")

# Number of cluster centers 
k <- 4

# Clustering using k-means
set.seed(fixed_seed)
km <- kmeans(personal_effects, centers = k)

# Every patient can be assigned to some cluster also based on how their personal reactions types

# - repeat same cluster placement for all the observations of same patient
observations_per_patient <- 4
sysdimet$effect_group <- unlist(lapply(km$cluster,rep,observations_per_patient)) 

# Plot the clusters
variations_data <- as.data.frame(t(km$centers))
#mebn.plot_clusters(variations_data, assumedpredictors, assumedtargets, largest_personal_effects, feature_index, sort_by_amount = TRUE)
cluster_index <- seq(1:k)
cluster_spread <- as.data.frame(table(km$cluster), stringsAsFactors = FALSE)

mebn.plot_clusters(variations_data, cluster_spread, cluster_index, assumedpredictors, assumedtargets, effects_with_most_variance, feature_index, sort_by_amount = TRUE)

```

By looking at the absolute effect of the cholesterol medication it seems that there separetes two groups where one it is a significant factor in explaining blood insulin level, and other group where it does not play virtually any role. But does these subjects even take cholesterol medications? Let's create a cross tabulation of observations to explore this effect more closely.

```{r cholmed_crosstab, echo=FALSE}

tb <- table(sysdimet$kolestrolilaakitys, sysdimet$effect_group)
rownames(tb) <- c("No medication", "Chol. med.")

kable(tb) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  column_spec(1, width = "10em") %>%
  row_spec(0,bold=TRUE) 
```

This indicates that subjects in clusters 2 and 4 are indeed taking cholesterol medication.

The average insulin concentrations in these clusters are

```{r, echo=FALSE}
clusters <- seq(1,4) 
fsins_avg <- c()

for (i in clusters) {
  fsins_avg <- c(fsins_avg, mean(sysdimet[sysdimet$effect_group == i,]$fsins))
}  

df <- cbind(clusters, fsins_avg)
colnames(df) <- c("cluster", "average blood insulin")

kable(df) %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  column_spec(1, width = "10em") %>%
  row_spec(0,bold=TRUE)   

```

There are 9 (=36/4) and 7 (=28/4) subjects in clusters 2 and 4 who are taking cholesterol medication. For subjects in the cluster 4 the average insulin level is  the medication seems to increase the insulin concentration quite much, but for subjects in the cluster 2 not much at all. 

**Clustering with nutritional effects only**

Both gender and cholesterol medication are unchanging factors at the dataset. Let us next remove those from clustering features and see how the clusters form based on nutritional effects only.

```{r nutrition_effect_clusters, echo=FALSE, eval=TRUE,message=FALSE, cache=TRUE}
feature_index <- feature_index[-c(match("sukupuoli", assumedpredictors$Name), 
                                  match("kolestrolilaakitys", assumedpredictors$Name))]


personal_variations_from_mean <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))
personal_effects <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))

#modelcache <- "BLMM_gamma/ar1/"
expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

for (i in c(1:nrow(assumedtargets)))
{
  targetname <- as.vector(assumedtargets[i,]$Name)
  
  modelcache <- expfam_ar1_dirs[expfam_ar1_dirs==targetname,]$modelcache
  
  target_blmm <- mebn.get_localfit(targetname, modelcache)
  posterior <- rstan::extract(target_blmm, pars = c("personal_effect", "b"))

  b_blmm <- colMeans(posterior$b)
  beta_b_blmm <- colMeans(posterior$personal_effect)
  
  # Omit predictor columns here, if needed
  # - b has intercept as first column, so the index needs to be adjusted
  b_blmm <- b_blmm[,feature_index+1] 
  beta_b_blmm <- beta_b_blmm[,feature_index] 
  
  if (i == 1) {
    # variance of the intercept is omitted
    personal_variations_from_mean <- b_blmm
    personal_effects <- beta_b_blmm
  }
  else
  {
    personal_variations_from_mean <- cbind(personal_variations_from_mean, b_blmm)
    personal_effects <- cbind(personal_effects, beta_b_blmm)
  }
}
```

```{r, echo=FALSE, eval=FALSE, cache=FALSE, fig.height=3}
# Number of clusters with nutritional effects only

library(stats)
library(gridExtra)

set.seed(fixed_seed)
k.max <- 8
wss_effects <- sapply(1:k.max, function(k){kmeans(personal_effects, k, nstart=50, iter.max = 15)$tot.withinss})
wss_vars <- sapply(1:k.max, function(k){kmeans(personal_variations_from_mean, k, nstart=50, iter.max = 15)$tot.withinss})

df_vars <- data.frame(x = 1:k.max, y = wss_vars)
df_effects <- data.frame(x = 1:k.max, y = wss_effects)

plot1 <- ggplot(data=df_effects, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference in absolute reaction") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

plot2 <- ggplot(data=df_vars, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference from typical behavior") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

gridExtra::grid.arrange(plot1,plot2,nrow=1)
```

```{r variation clusters3, echo=FALSE, eval=TRUE, fig.width=4, fig.height=5, cache=TRUE}
source("mebn/MEBN.r")
# Number of cluster centers 
k <- 4

# Clustering using k-means
set.seed(fixed_seed)
km <- kmeans(personal_variations_from_mean, centers = k)

# Every subject can be assigned to some cluster based on how their reactions differ from average
sysdimet$variation_group <- km$cluster 

# Plot the clusters
variations_data <- as.data.frame(t(km$centers))
cluster_index <- seq(1:k)

cluster_spread <- as.data.frame(table(km$cluster), stringsAsFactors = FALSE)
mebn.plot_clusters(variations_data, cluster_spread, cluster_index, assumedpredictors, assumedtargets, effects_with_most_variance, feature_index, sort_by_amount = TRUE)
```


```{r personal_effect_clusters_nutrients, echo=FALSE, eval=TRUE, fig.width=4, fig.height=5, cache=TRUE}

# Number of cluster centers 
k <- 4

# Clustering using k-means
set.seed(fixed_seed)
km <- kmeans(personal_effects, centers = k)

# Every subject can be assigned to some cluster also based on how their personal reactions types

# - repeat same cluster placement for all the observations of same subject
observations_per_patient <- 4
sysdimet$effect_group <- unlist(lapply(km$cluster,rep,observations_per_patient)) 

# Plot the clusters
cluster_data <- as.data.frame(t(km$centers))
cluster_index <- seq(1:k)
cluster_spread <- as.data.frame(table(km$cluster), stringsAsFactors = FALSE)

mebn.plot_clusters(cluster_data, cluster_spread, cluster_index, assumedpredictors, assumedtargets, effects_with_most_variance, feature_index)
```

In clusters 1 and 2 there are subjects whose insulin concentrations decrease and increase more than on average.

# Personally predicted reaction types

During the cross-validation we estimated personal models for each subject. Next we illustrate the differences within personal reaction types by picking few most distant ones. 

```{r mufa_differences, echo=FALSE, eval=TRUE, message=FALSE}
p <- nrow(assumedpredictors)
ins_idx <- match("fsins", assumedtargets$Name)
mufa_idx <- match("mufa", assumedpredictors$Name)

mufa_fsins_idx <- p*(ins_idx-1) + mufa_idx

# mufa -> fsins for every subject
mufa_fsins <- as.data.frame(cbind(personal_effects[, mufa_fsins_idx], seq(1, nrow(personal_effects))))
colnames(mufa_fsins) <- c("effect", "subject_number")

ordered_mufa_fsins <- mufa_fsins[order(-mufa_fsins$effect),]

person_id1 <- head(ordered_mufa_fsins$subject_number,1)
person_id2 <- tail(ordered_mufa_fsins$subject_number,1)

#What reaction clusters these subjects belong?
#sysdimet[person_id1,]$effect_group   # patient 1 (S01) -> cluster 3
#sysdimet[person_id2,]$effect_group   # patient 43 (S104) -> cluster 2  

#mean(sysdimet[sysdimet$SUBJECT_ID == 'S104',]$fsins)person_id2
```

```{r personal_graph1, echo=FALSE, eval=TRUE}
source("mebn/MEBN.r")

initial_graph <- mebn.new_graph_with_randomvariables(datadesc)

expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

# subject 1 (S01) -> cluster 3
personal_graph1 <- mebn.personal_graph(person_id = person_id1, 
                                       reaction_graph = initial_graph, 
                                       predictor_columns = assumedpredictors, 
                                       assumed_targets = assumedtargets, 
                                       local_distributions = expfam_ar1_dirs)

write.graph(personal_graph1, "graphs/personal_insample_graph_s01.graphml", "graphml")
```

```{r personal_graph2, echo=FALSE, eval=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)

expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

# subject 43 (S104) -> cluster 2
personal_graph2 <- mebn.personal_graph(person_id = person_id2, 
                                       reaction_graph = initial_graph, 
                                       predictor_columns = assumedpredictors, 
                                       assumed_targets = assumedtargets, 
                                       local_distributions = expfam_ar1_dirs)

write.graph(personal_graph2, "graphs/personal_insample_graph_s104.graphml", "graphml")
```

We can then compare the visualizations of the personal reaction graphs. The effect of cholesterol medication is most significant difference, but other differences exist as well.

```{r personal_graphs_comparison, eval=TRUE, fig.height = 8, fig.width = 5, fig.align = "left", echo=FALSE, message=FALSE, warning=FALSE}
source("mebn/MEBN.r")
require(igraph)
personal_graph1 <- read.graph("graphs/personal_insample_graph_s01.graphml", "graphml")
personal_graph2 <- read.graph("graphs/personal_insample_graph_s104.graphml", "graphml")

par(mfrow=c(2,1))
layout <- mebn.plot_personal_effects(personal_graph1, 10, graph_layout, colorImage = !RenderArticleFigures)
title("Subject 1 from cluster 3",cex.main=0.7)
layout <- mebn.plot_personal_effects(personal_graph2, 10, graph_layout, colorImage = !RenderArticleFigures)
title("Subject 2 from cluster 2",cex.main=0.7)
```

```{r, echo=FALSE}
personal_effect <- function(effect, patient, p_graph){
  effv <- V(p_graph)[name = paste0("personal_",effect)]
  eff <- c(patient, effect, effv$value_lCI, effv$value, effv$value_uCI)
  return(eff)
}

pe <- personal_effect("safa_fsins", 1, personal_graph1)
pe <- rbind(pe, personal_effect("safa_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("ligniini_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("ligniini_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("cvit_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("cvit_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("dvit_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("dvit_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("energia_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("energia_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("epa_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("epa_fsins", 2, personal_graph2))

colnames(pe)<-c("Patient", "Effect", "Lower-CI", "Mean value", "Upper-CI")

kable(pe) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)

#kable(pe, "latex", booktabs = T, caption = "") %>%
#  kable_styling(latex_options = c("striped", "condensed"), full_width = TRUE) %>%
#  row_spec(0,bold=TRUE)

```


# References