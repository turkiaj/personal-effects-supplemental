---
title: |
  | Mixed-Effect Bayesian Network Reveals 
  | Personal Effects of Nutrition
author:
- JARI TURKIA \textsuperscript{1,2}
- LAURI MEHTÄTALO \textsuperscript{1,3}
- URSULA SCHWAB \textsuperscript{4,5}
- VILLE HAUTAMÄKI \textsuperscript{1}
- \textsuperscript{1} School of Computing, University of Eastern Finland, 80101 Joensuu, Finland
- \textsuperscript{2} CGI Suomi, Joensuu, Finland
- \textsuperscript{3} Natural Resources Institute Finland (Luke), Bioeconomy and Environment Unit,
- Yliopistokatu 6, 80101 Joensuu, Finland
- \textsuperscript{4} School of Medicine, Institute of Public Health and Clinical Nutrition,
- University of Eastern Finland, Kuopio, Finland
- \textsuperscript{5} Department of Medicine, Endocrinology and Clinical Nutrition,
- Kuopio University Hospital, Kuopio, Finland
bibliography: biblio.bib
output: 
  pdf_document:
    latex_engine: xelatex
    fig_caption: yes
    includes:
      in_header: custom_figure_captions.tex
  word_document: default
  html_document: default
subtitle: Supplementary Materials
abstract: This notebook is supplementary material for the article "Mixed-Effect Bayesian
  Network Reveals Personal Effects of Nutrition". The notebook shows in
  detail how mixed-effect Bayesian network is constructed and how it is used to model
  the effects of nutrition. The hierarchical structure of the network model allows
  studying the effects in both typical and personal levels. In addition, it is shown
  that the personal effects form clusters of similarly behaving subjects. Finally,
  personal networks are predicted for unseen subjects with cross-validation. This
  shows that there exist personal differences in nutrional effects, and they can be
  detected from repeated observations of food records and blood concentrations.
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra) # for HTML and Latex tables

knitr::opts_chunk$set(echo = TRUE, fig.align="center")

# this allows using tikz rendering for plots with "dev=tikz"
knit_hooks$set(plot = function(x, options) {
  if ('tikz' %in% options$dev && !options$external) {
    hook_plot_tex(x, options)
  } else hook_plot_md(x, options)
})

# Fix seed for random number generator for getting consistent results in kmeans etc.
fixed_seed <- 678

# Load common MEBN package
source("mebn/MEBN.r")

# Online version (TRUE) uses color images while (FALSE) renders exact figures for the article 
RenderArticleFigures <- FALSE
```

In this work we propose Bayesian network as an appealing way to model and predict the effects of nutrition. Bayesian networks are directed graphical models that describe a joint probability distribution where nodes of the graph are random variables and edges between the nodes form a conditional probability structure. In nutritional modeling we assign nutritional composition of subjects' diet and different blood concentrations as those random variables, and study the connections between them. The goal is then to find such connections for the graph that most probably describe the correct conditional relationships between nutrients and their effects.

# Personal nutrition data

We analyze a dataset from the Sysdimet study [@pmid21901116] that contains four repeated measurements of 17 nutrients, some basic information about the subject (gender, medication) and their corresponding blood concentrations, from 106 individuals. 

```{r data_loading, echo=FALSE, message=FALSE}

# Read the data description
datadesc <- read.csv(file="data/SYSDIMET_data_description.csv", header = TRUE, sep = ";")

# Read the actual data matching the description
sysdimet <- read.csv(file="data/SYSDIMET_diet.csv", sep=";", dec=",")

# Define how to iterate through the graph
assumedpredictors <- datadesc[datadesc$Order==100,]    
assumedtargets <- datadesc[datadesc$Order==200,] 
```

Following spaghetti plots show the progress of blood concentrations during the 12-week study. Measurements of only ten from 106 subjects are shown at the plots for clarity. Our goal is to predict next personal blood concentration when subject's diet from past weeks is known.

```{r spagettiplot_data, echo=FALSE, warning=FALSE}
sysdimet$SUBJECT_ID <- factor(sysdimet$SUBJECT_ID)
plot_patients_index <- seq(1, length(levels(sysdimet$SUBJECT_ID)), by=5)
plot_patients <- levels(sysdimet$SUBJECT_ID)[plot_patients_index]

sysdimet_every_10th <- sysdimet[sysdimet$SUBJECT_ID %in% plot_patients,]
```

```{r spagettiplot_fshdl, eval = FALSE, echo=FALSE, fig.align="left", fig.height=2, fig.width=5, message=FALSE}
library(ggplot2)
library(gridExtra)

# Fig. 1 in the article

hdlplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fshdl, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_continuous(breaks=c(-1,0,3,4,7,8,11,12)) +
  geom_vline(xintercept =c(0,4,8,12)) + 
  annotate("rect",xmin=c(-1,3,7,11), xmax=c(0,4,8,12), ymin=-Inf, ymax=Inf, alpha = .2) + 
  annotate("text", x = -0.5, y = 1.4, label = "Food record keeping", angle = 90) +
  annotate("text", x = 3.5, y = 1.4, label = "Food record keeping", angle = 90) +
  annotate("text", x = 7.5, y = 1.4, label = "Food record keeping", angle = 90) +
  annotate("text", x = 11.5, y = 1.4, label = "Food record keeping", angle = 90) +
  labs(x = "Study timeline with lab. measurements in weeks 0,4,8, and 12", y = "HDL-chol. (mmol/l)") 
  
  #scale_colour_grey() +
  #theme_bw()

  #ggsave("figures/spagettiplot_fshdl-1.pdf", plot = hdlplot, width = 5, height = 2.5)

#hdlplot
```

```{r spagettiplot, echo=FALSE, fig.align="left", fig.height=10, fig.width=6, message=FALSE, fig.cap="Progress of concentration levels during the 12-week study. Measurements were taken at weeks 0, 4, 8, and 12, and the food records were kept during the week before the measurement. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org)."}
library(ggplot2)
library(gridExtra)

hdlplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fshdl, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_continuous(breaks=c(-1,0,3,4,7,8,11,12)) +
  geom_vline(xintercept =c(0,4,8,12)) + 
  annotate("rect",xmin=c(-1,3,7,11), xmax=c(0,4,8,12), ymin=-Inf, ymax=Inf, alpha = .2) + 
  annotate("text", x = -0.5, y = 1.4, label = "Food record keeping", angle = 90) +
  annotate("text", x = 3.5, y = 1.4, label = "Food record keeping", angle = 90) +
  annotate("text", x = 7.5, y = 1.4, label = "Food record keeping", angle = 90) +
  annotate("text", x = 11.5, y = 1.4, label = "Food record keeping", angle = 90) +
  labs(x = "Week", y = "HDL-chol. (mmol/l)") + theme(axis.title.x = element_blank())

ldlplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fsldl, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_continuous(breaks=c(-1,0,3,4,7,8,11,12)) +
  geom_vline(xintercept =c(0,4,8,12)) + 
  annotate("rect",xmin=c(-1,3,7,11), xmax=c(0,4,8,12), ymin=-Inf, ymax=Inf, alpha = .2) + 
  annotate("text", x = -0.5, y = 3.8, label = "Food record keeping", angle = 90) +
  annotate("text", x = 3.5, y = 3.8, label = "Food record keeping", angle = 90) +
  annotate("text", x = 7.5, y = 3.8, label = "Food record keeping", angle = 90) +
  annotate("text", x = 11.5, y = 3.8, label = "Food record keeping", angle = 90) +
  labs(x = "Week", y = "LDL-chol. (mmol/l)") + theme(axis.title.x = element_blank())

insplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fsins, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_continuous(breaks=c(-1,0,3,4,7,8,11,12)) +
  geom_vline(xintercept =c(0,4,8,12)) + 
  annotate("rect",xmin=c(-1,3,7,11), xmax=c(0,4,8,12), ymin=-Inf, ymax=Inf, alpha = .2) + 
  annotate("text", x = -0.5, y = 20, label = "Food record keeping", angle = 90) +
  annotate("text", x = 3.5, y = 20, label = "Food record keeping", angle = 90) +
  annotate("text", x = 7.5, y = 20, label = "Food record keeping", angle = 90) +
  annotate("text", x = 11.5, y = 20, label = "Food record keeping", angle = 90) +
  labs(x = "Week", y = "Insulin (mU/l)") + theme(axis.title.x = element_blank())

kolplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fskol, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_continuous(breaks=c(-1,0,3,4,7,8,11,12)) +
  geom_vline(xintercept =c(0,4,8,12)) + 
  annotate("rect",xmin=c(-1,3,7,11), xmax=c(0,4,8,12), ymin=-Inf, ymax=Inf, alpha = .2) + 
  annotate("text", x = -0.5, y = 5.5, label = "Food record keeping", angle = 90) +
  annotate("text", x = 3.5, y = 5.5, label = "Food record keeping", angle = 90) +
  annotate("text", x = 7.5, y = 5.5, label = "Food record keeping", angle = 90) +
  annotate("text", x = 11.5, y = 5.5, label = "Food record keeping", angle = 90) +
  labs(x = "Week", y = "Total chol. (mmol/l)") + theme(axis.title.x = element_blank())

glukplot <- ggplot() +
  geom_line(data=sysdimet_every_10th, aes(y = fpgluk, x=WEEK, color=SUBJECT_ID), size=0.6, show.legend = FALSE) +
  scale_x_continuous(breaks=c(-1,0,3,4,7,8,11,12)) +
  geom_vline(xintercept =c(0,4,8,12)) + 
  annotate("rect",xmin=c(-1,3,7,11), xmax=c(0,4,8,12), ymin=-Inf, ymax=Inf, alpha = .2) + 
  annotate("text", x = -0.5, y = 6.5, label = "Food record keeping", angle = 90) +
  annotate("text", x = 3.5, y = 6.5, label = "Food record keeping", angle = 90) +
  annotate("text", x = 7.5, y = 6.5, label = "Food record keeping", angle = 90) +
  annotate("text", x = 11.5, y = 6.5, label = "Food record keeping", angle = 90) +
  labs(x = "Study timeline with laboratory measurements in weeks 0,4,8, and 12", y = "Glucose (mmol/l)") 

grid.arrange(hdlplot, ldlplot, kolplot, insplot, glukplot, nrow = 5, ncol=1, padding=0) 

```

When the future direction of the blood concentrations can be predicted, the typical and personal importance of nutrients contributing this change be estimated from the model parameters. 

# Mixed-effect Bayesian network

We focus only on two-level, bipartite, graphs where nutrients and personal details are assumed to affect blood concentrations, and only the magnitude of the effect is left to be estimated. 

```{r graph, fig.height = 4, fig.width=5, echo=FALSE, fig.align = "left", fig.cap="Initial, bi-partite, network structure. The figure is plotted with iGraph package for R language (v 1.2.6, https://igraph.org/r).", echo=FALSE, message=FALSE}
library(igraph)
initial_graph <- mebn.fully_connected_bipartite_graph(datadesc)

V(initial_graph)$size = 10 

# - put all blood concentrations in own rank
bipa_layout <- layout_as_bipartite(initial_graph, types = V(initial_graph)$type == "100")
# - flip layout sideways, from left to right
gap <- 6
bipa_layout <- cbind(bipa_layout[,2]*gap, bipa_layout[,1])

V(initial_graph)[V(initial_graph)$type == "100"]$label.degree = pi # left side
V(initial_graph)[V(initial_graph)$type == "200"]$label.degree = 0 # right side

plot(initial_graph,
       layout=bipa_layout, 
       rescale=TRUE,
       vertex.label.color="black",
       vertex.label.cex=0.7,
       vertex.label.dist=3.8,
       edge.arrow.size=0.5,
       edge.arrow.width=1,
       axes=FALSE,
       margin=0,
       layout.par = par(mar=c(0,0,0,0)))

```

We assume a connection from every nutrient and personal information to every blood concentration value at the dataset. The model search is then focused on to estimating optimal coefficients describing the connections. 

# Model development

Our starting assumption is that both nutrients and the blood concentrations are normally distributed. This assumption may be naive as it allows the blood concentrations to have negative values. We normalize all the input values to same scale, so that the estimated regression coefficients can be used as a indicators of connection strenght.

```{r graph_with_normal_rvs, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
sysdimet_normal <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                         inputdata = sysdimet,
                                         predictor_columns = assumedpredictors, 
                                         assumed_targets = assumedtargets, 
                                         group_column = "SUBJECT_ID",
                                         local_estimation = mebn.sampling,
                                         local_model_cache = "models/BLMM_normal", 
                                         stan_model_file = "mebn/BLMM_normal.stan",
                                         normalize_values = TRUE)

```

```{r write_graph_with_normal_rvs, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
write.graph(sysdimet_normal, "graphs/sysdimet_normal.graphml", "graphml")
```

Here we evaluate the fit of model candidates visually by plotting the posterior predictive distributions (PPC) over the distributions of the true blood concentrations. As expected, normal distribution in random variables is not fitting well. Normal distribution allows non-zero probability for negative blood concentrations resulting the probability to leak for impossible values. Normal distribution is also symmetric while the distributions of blood concentrations are usually more skewed to right. 

```{r normal_model_ppc, fig.height = 4, fig.width=5, fig.cap="Visual posterior predictive check of local distributions with normal distribution. The figure is plotted with bayesplot package for R language (v 1.7.3, https://mc-stan.org/bayesplot).", echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
mebn.target_dens_overlays("BLMM_normal/", assumedtargets, sysdimet)
```


## Developing the model beyond normal distributions

More realistic probability distribution for blood concentrations would be Log-Normal or Gamma distributions [@10.1371/journal.pone.0021403]. They both allow only positive values and model better the right tail of individual larger values. For further development, we choose Gamma distribution with identity link function. This is important as it keeps the regression coefficients of the nutrients on the same absolute scale than with Normal models. The regression coefficients are used as weights of the edges at the Bayesian network and they all should be on the same scale regardless of the random variables' distribution. 

```{r graph_with_gamma_response, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
initial_gamma_graph <- mebn.new_graph_with_randomvariables(datadesc)

sysdimet_gamma <- mebn.bipartite_model(reaction_graph = initial_gamma_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma", 
                                   stan_model_file = "mebn/BLMM_gamma.stan",
                                   normalize_values = TRUE)
```

```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
write.graph(sysdimet_gamma, "graphs/sysdimet_gamma.graphml", "graphml")
```

The visual comparison of the true and estimated distributions of blood concenrations shows that Gamma distribution follows the true distributions quite well. 

```{r gamma_ppc, fig.height = 4, fig.width=5, fig.cap="Visual posterior predictive check of local distributions with Gamma distribution. The figure is plotted with bayesplot package for R language (v 1.7.3, https://mc-stan.org/bayesplot).", echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=FALSE}
mebn.target_dens_overlays("BLMM_gamma/", assumedtargets, sysdimet)
```

The visual PPC inspection shows that the Gamma distribution fit generally better to responses than Normal distribution, but cholesterol concentrations are still systematically estimated too low (fsldl and fskol) or too high (fshdl).

## Modeling correlated observations with an autocorrelation process

In the dataset the observations from subjects' food records and blood concentrations have one week response time. This might not be optimal time for all the responses and the successive observations might be correlated. For modeling the correlated observations, we add an autocorrelation process to the model by adding an estimated portion of previous measurement to the linear predictor

```
mu[n] += Y[n-1] * ar1
```      

This coefficient 'ar1' is estimated separately for each response

```{r graph_with_gamma_ar1, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_gamma_ar1 <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_gamma/ar1", 
                                   stan_model_file = "mebn/BLMM_gamma_ar1.stan",
                                   normalize_values = TRUE)

mebn.write_gexf(sysdimet_gamma_ar1, "graphs/sysdimet_gamma_ar1.gexf")
write_graph(sysdimet_gamma_ar1, "graphs/sysdimet_gamma_ar1.graphml", "graphml")

```

The autocorrelation structure seems to decrease the variance of the model and correcting the systematical estimation errors from the previous model candidate

```{r gamma_ar1_ppc, fig.height = 4, fig.width=5, fig.cap="Visual posterior predictive check of local distributions with Gamma distribution and first-order autocorrelation process. The figure is plotted with bayesplot package for R language (v 1.7.3, https://mc-stan.org/bayesplot).", echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1/", assumedtargets, sysdimet)
```


It is interesting also to compare the AR(1) coefficients of different local distributions at the graph. Blood insulin (fsins) has largest AR(1) coefficient indicating that successive measurements are most correlated and the values are not changing as rapidly as with other measurements. Credible interval for cholesterol measurements includes zero indicating that autocorrelation is very low or non-existent between two measurements.

```{r ar1_comparison, fig.cap="Comparison of autocorrelation coefficients of different concentrations.", message=FALSE, warning=FALSE, cache=TRUE}
ar1_comparison <- mebn.AR_comparison(assumedtargets, "BLMM_gamma/ar1")
```
```{r ar1_comparison_table, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.height=5}
kable(ar1_comparison, caption="Comparison of autocorrelation coefficients for each distribution.") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)
```

## Skrinkage prior model

In our analysis, we use two models: 1) typical effects are better shown with previous model that has vague prior on beta coefficients, and 2) personal effects became clearer in a model that uses shrinkage prior on beta coefficients. This shrinkaged model is also faster to evaluate in k-fold setting and is possibly a better predictor.

The predictive ability of the model might be reduced if the model overfits to small nuances of the dataset. To overcome the possible overfitting, we apply a shrinkage prior "Regularized Horseshoe Shrinkage (RHS)" [@Piironen2017a], also called Finnish horseshoe, on regression coefficients. It allows specifying a prior knowledge, or at least an educated guess, about the number of significant predictors for a target. Here we assume that one third of the nutrients might be relevant for any given blood concenration, and apply following parameters for the shrinkage

```{r shrinkage_parameters, echo=TRUE, message=FALSE}
shrinkage_parameters <- within(list(),
{
    scale_icept  <- 1         # prior std for the intercept
    scale_global <- 0.02266   # scale for the half-t prior for tau: 
                              # ((p0=7) / (D=22-7)) * (sigma = 1 / sqrt(n=106*4))
    nu_global    <- 1         # degrees of freedom for the half-t priors for tau
    nu_local     <- 1         # degrees of freedom for the half-t priors for lambdas
    slab_scale   <- 1         # slab scale for the regularized horseshoe
    slab_df      <- 1         # slab degrees of freedom for the regularized horseshoe           
})
```

Next we fit the previous model with the Finnish horseshoe added. Besides the shrinkage parameters, we provide now the data in two sets: input data for estimation and target data to hold out for prediction. 

```{r noholdout_index}
# One RHS model with all data (no_holdout)
holdout_index <- rep(0, nrow(sysdimet))
```

```{r BLMM_gamma_ar1_rhs_cv_ppc, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_gamma_ar1_rhs_pred <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   targetdata = holdout_index,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = assumedtargets, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = paste0("models/BLMM_gamma/ar1_rhs/no_holdout"), 
                                   stan_model_file = "mebn/BLMM_gamma_ar1_rhs_cv_ppc.stan",
                                   reg_params = shrinkage_parameters,
                                   normalize_values = TRUE)


write.graph(sysdimet_gamma_ar1_rhs_pred, "graphs/sysdimet_gamma_ar1_rhs.graphml", "graphml")
```

```{r gamma_ar1_rhs_ppc, fig.cap="Visual posterior predictive check of local distributions with Gamma AR(1) distribution and regularized horseshoe prior on common effect coefficients. The figure is plotted with bayesplot package for R language (v 1.7.3, https://mc-stan.org/bayesplot).", echo=FALSE, fig.height = 4, fig.width=5, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
mebn.target_dens_overlays("BLMM_gamma/ar1_rhs/no_holdout/", assumedtargets, sysdimet)
```

Visual comparison with posterior predictive check seem to favor this model. Let us confirm the evaluation with numerical metrics.

# Evaluation of the models' fit and predictive performance

Different model versions are compared with a normalized root mean squared error (NRMSE) and also with a classification test that allows comparison with other classification methods.

## Comparison with in-sample data

Following compares different model candidates by using normalized root mean squared error (NRMSE) metrics. Normalization allows comparing the prediction accuracy of responses with different scales.

```{r NRMSE comparison, eval=FALSE, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
source("model_eval_functions.r")

allrep_normal <- get_rep_response_for_all("models/BLMM_normal/")
allrep_gamma <- get_rep_response_for_all("models/BLMM_gamma/")
allrep_rhs <- get_rep_response_for_all("models/BLMM_gamma/ar1_rhs/no_holdout/")
allrep_norhs <- get_rep_response_for_all("models/BLMM_gamma/ar1/")

# Normal distribution model
nrmse.mat <- matrix(0, nrow=0,ncol=7)
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_normal, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- sqrt((rep_response - true_response)^2)
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Normal", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

# Gamma distribution model without autocorrelation

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_gamma, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Gamma", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

# Gamma model with AR(1) structure

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_norhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Gamma AR(1)", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

# Gamma model with AR(1) structure and RHS prior on betas

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_rhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("Gamma AR(1) RHS", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

colnames(nrmse.mat)[1] <- "model"
colnames(nrmse.mat)[7] <- "mean"

saveRDS(nrmse.mat, "evaluations/NRMSE-matrix1.rds")
```

```{r model_nrmse1, fig.cap="Comparison of NRMSE errors between model versions and their local distributions. ", echo=FALSE, message=FALSE, warning=FALSE, eval=FALSE}
nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix1.rds")

kable(nrmse.mat) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)

#kable(nrmse.mat, "latex", booktabs = T, caption = "Predictive accuracy percents for correct direction of change") %>%
#  kable_styling(latex_options = c("striped", "condensed"), full_width = TRUE) %>%
#  row_spec(0,bold=TRUE)

```

```{r graph_with_normal_ar1, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}

# We can fit local distribution for fsins separately by defining a Bayesian network with just this one response node. 
# In following chunks, we fit both non-shrinked and regularized horseshoe-shrinked versions of Normal AR(1) model.

initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
only_fsins <- assumedtargets[assumedtargets$Name=="fsins",]

fsins_normal_ar1 <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = only_fsins, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = "models/BLMM_normal/ar1", 
                                   stan_model_file = "mebn/BLMM_normal_ar1.stan",
                                   normalize_values = TRUE)

```

```{r graph_with_normal_ar1_rhs, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# One RHS model with all data (no_holdout)
holdout_index <- rep(0, nrow(sysdimet))
```
```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
only_fsins <- assumedtargets[assumedtargets$Name=="fsins",]

fsins_normal_ar1_rhs <- mebn.bipartite_model(reaction_graph = initial_graph, 
                                   inputdata = sysdimet,
                                   targetdata = holdout_index,
                                   predictor_columns = assumedpredictors, 
                                   assumed_targets = only_fsins, 
                                   group_column = "SUBJECT_ID",
                                   local_estimation = mebn.sampling,
                                   local_model_cache = paste0("models/BLMM_normal/ar1_rhs/no_holdout"), 
                                   stan_model_file = "mebn/BLMM_normal_ar1_rhs_cv_ppc.stan",
                                   reg_params = shrinkage_parameters,
                                   normalize_values = TRUE)

``` 


```{r fsins_comparison, fig.height = 3, fig.width=5, fig.cap="Plot on the left is a PPC of Gamma distributed fsins-response and the right plot is a normally distributed response that fits better with lower mean squared error. The figure is plotted with bayesplot package for R language (v 1.7.3, https://mc-stan.org/bayesplot).", echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
library(gridExtra)

only_fsins <- assumedtargets[assumedtargets$Name=="fsins",]
gamma_plot <- mebn.target_dens_overlays("BLMM_gamma/ar1_rhs/no_holdout/", only_fsins, sysdimet)
normal_plot <- mebn.target_dens_overlays("BLMM_normal/ar1_rhs/no_holdout/", only_fsins, sysdimet)

grid.arrange(gamma_plot, normal_plot,  nrow = 1, widths=c(2,2), padding=0)
```

Next, we contruct a EXPFAM AR(1) model that has this normally distributed fsins-response and otherwise Gamma distributed blood concentration responses. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Other local distributions use Gamma AR1 model, but fsins uses Normal AR1
expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

expfam_ar1_rhs_dirs <- assumedtargets
expfam_ar1_rhs_dirs$modelcache <- "models/BLMM_gamma/ar1_rhs/no_holdout"
expfam_ar1_rhs_dirs[expfam_ar1_rhs_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1_rhs/no_holdout"
```

```{r expfam_ar1_rhs_ppc, echo=FALSE, fig.height = 4, fig.width=5, message=FALSE, warning=FALSE, eval=FALSE, cache=FALSE, fig.cap="Visual posterior predictive check of local distributions with normal distribution on fsins-response and Gamma AR(1) distribution on the others. Regularized horseshoe prior is used on common effect coefficients. This model is denoted as EXPFAM AR(1) in the rest of the analysis. The figure is plotted with bayesplot package for R language (v 1.7.3, https://mc-stan.org/bayesplot)."}
source("mebn/MEBN.r")

expfam_ar1_rhs_dirs2 <- assumedtargets
expfam_ar1_rhs_dirs2$modelcache <- "BLMM_gamma/ar1_rhs/no_holdout"
expfam_ar1_rhs_dirs2[expfam_ar1_rhs_dirs2$Name=="fsins",]$modelcache <- "BLMM_normal/ar1_rhs/no_holdout"

mebn.expfam_dens_overlays(expfam_ar1_rhs_dirs2, assumedtargets, sysdimet)
```


```{r nrmse_expfam, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
source("model_eval_functions.r")
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))
nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix1.rds")

## EXPFAM AR(1)

allrep_expfam_ar1 <- get_rep_response_for_expfam(expfam_ar1_dirs)

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_expfam_ar1, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("EXPFAM AR(1)", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

## EXPFAM AR(1) RHS

allrep_expfam_ar1_rhs <- get_rep_response_for_expfam(expfam_ar1_rhs_dirs)

personal_nrmse <- matrix(0, nrow=0,ncol=5)
for (subject_number in 1:amount_subjects)
{
  rep_response <- get_rep_response(allrep_expfam_ar1_rhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  #nrmse_rows <- (rep_response - true_response)^2
  nrmse_rows <- mebn.NRMSE(rep_response, true_response, mean(true_response))
  nrmse <- rowMeans(nrmse_rows)
  
  personal_nrmse <- rbind(personal_nrmse, nrmse)
}

model_nrmse <- mean(colMeans(personal_nrmse))
nrmse.mat <- rbind(nrmse.mat, c("EXPFAM AR(1) RHS", round(colMeans(personal_nrmse), 3), round(model_nrmse, 3)))

saveRDS(nrmse.mat, "evaluations/NRMSE-matrix2.rds")
```

```{r expfam_ar1_model, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_expfam_ar1 <- mebn.bipartite_expfam_bn(initial_graph, assumedpredictors, assumedtargets, expfam_ar1_dirs)

write.graph(sysdimet_expfam_ar1, "graphs/sysdimet_expfam_ar1.graphml", "graphml")
```

```{r expfam_ar1_rhs_model, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)
sysdimet_expfam_ar1_rhs <- mebn.bipartite_expfam_bn(initial_graph, assumedpredictors, assumedtargets, expfam_ar1_rhs_dirs)

write.graph(sysdimet_expfam_ar1_rhs, "graphs/sysdimet_expfam_ar1_rhs.graphml", "graphml")
```

## Predictive accuracy cross-validated MEBN 

Execution of the k-fold cross-validation is done in a separated notebook (cross-validation.Rmd) as it takes substantial amount of time to run. The results are stored and load for analysis here. For the cross-validation we partitioned the observations in data to 12 partitions for weeks 4,8 and 12. Then each of the data partitions in turn is left out from model estimation. This allows us to make predictions for unseen data. 

```{r model_mse3, echo=FALSE}
# Cross-validation.Rmd adds CV evaluations to NRMSE-matrix3.rds
```

```{r model_nrmse2, fig.cap="Each of the model candidates are compared here with a normalized root mean squared error (NRMSE) and last final versions (Gamma AR(1) RHS CV and Expfam AR(1) RHS CV) are evaluated with the cross-validation.", echo=FALSE, message=FALSE, warning=FALSE}
nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix3.rds")

#colnames(nrmse.mat) <- c("Model", "fS-HDL", "fS-LDL","fS-Ins","fs-Chol","fP-Gluc","BN Mean")
colnames(nrmse.mat) <- c("Model", "HDL-chol.", "LDL-chol.","Insulin","Total chol.","Glucose","BN Mean")

# Round to two decimals as the measurements
nrmse.mat[,2:7] <- round(as.numeric(nrmse.mat[,2:7]),2)

#kable(nrmse.mat) %>%
#  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
#  row_spec(0,bold=TRUE)

kable(nrmse.mat, "latex", booktabs = T, caption = "Model candidates were compared with a normalized root mean squared error (NRMSE) separately for each concentration and with mean accuracy of whole Bayesian network. The last final versions (Gamma AR(1) RHS CV and Expfam AR(1) RHS CV) were evaluated with the cross-validation.") %>%
  add_header_above(c(" " = 2,"NRMSE" = 6)) %>%
  kable_styling(latex_options = c("basic", "condensed"), full_width = FALSE) %>%
  row_spec(0,bold=TRUE) %>%
  column_spec(2, width = "13em")
#  save_kable(file = "tables/NRMSE_comparison_table.pdf", keep_tex = TRUE)
```

```{r nrmse_plot_vertical, fig.cap="Comparison of NRMSE metrics of different model versions. Normaized error is measured each local concentration distribution and for the whole network as mean of local distribution errors. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org).", fig.height = 3, fig.width = 5, echo=FALSE, fig.align = "left", message=FALSE, warning=FALSE, cache=TRUE}
library(ggplot2)

nrmse.mat <- readRDS(file="evaluations/NRMSE-matrix3.rds")
nrmse.df <- data.frame(nrmse.mat[,1])

# model is a string factors, NRMSEs are doubles
nrmse.df$model <- factor(nrmse.mat[,1], levels = rev(c("Normal","Gamma","Gamma AR(1)","Gamma AR(1) RHS","EXPFAM AR(1)","EXPFAM AR(1) RHS", "Gamma AR(1) RHS CV", "EXPFAM AR(1) RHS CV")))
nrmse.df <- cbind(nrmse.df, apply(nrmse.mat[,2:7], 2, as.numeric))[,2:8]

#label.df <- as.data.frame(paste0(colnames(nrmse.mat)[2:7], " ", sprintf(as.numeric(nrmse.mat[6,2:7]), fmt = '%#.3f')))
#label.df <- as.data.frame(colnames(nrmse.mat)[2:7])
label.df <- as.data.frame(c("cholesterol","","insulin","","glocose","mean"))
label.df <- cbind(label.df, as.numeric(nrmse.mat[7,2:7]))
colnames(label.df) <- c("label", "value")

ggplot(nrmse.df, show.legend = FALSE) +
  geom_line(aes(y = fshdl, x = model, group=1), size=0.3) +
  geom_line(aes(y = fsldl, x = model, group=1), size=0.3) +
  geom_line(aes(y = fsins, x = model, group=1), size=0.3) +
  geom_line(aes(y = fskol, x = model, group=1), size=0.3) +
  geom_line(aes(y = fpgluk, x = model, group=1), size=0.3) +
  geom_line(aes(y = mean, x = model, group=1), size=1) +
  geom_text(data = label.df, aes(label = label, x = "EXPFAM AR(1) RHS CV", y = value, hjust = .2, vjust = (label == "glocose")*1.0+1.0), size = 3) +
  scale_y_continuous() +
  labs(x = "", y = "NRMSE") + 
  coord_flip() +
  theme_bw() +
  theme(axis.text.x=element_text(size=rel(0.9)), plot.margin = margin(0,3,0,0)) 

```


# Evaluation with classification metrics

Normalized root mean squared error (NRMSE) is good for comparing model candidates, but it does not say much about the actual usefulness of the model. For personal nutrition guiding, it is important to predict how given diet will affect the future blood concentration values. In the standard NRMSE comparison, the error between true and predicted values were compared, but a custom classification test can be also used. It tells if the given diet raises or lowers the future blood concentrations compared to past measurement. 

Classification test allows also to compare MEBN with other classification methods. XGBoost is a well-performing decision tree method. It is a non-parametric machine learning method that learns personal reactions only by example. Following compares the cross-validated predictive accuracy of XGBoost with MEBN predictions (MEBN CV) that uses EXPFAM AR(1) RHS-model. Also in-sample MEBN fit with non-shrinked EXPFAM AR(1) is given for comparison. This best predicting model is used for dataset analysis at rest of this notebook.      

```{r expfam_ar1_accuracy, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
source("model_eval_functions.r")

# Summary matrix for AR(1) NON-RHS model with in-sample data

class.mat <- matrix(0, nrow=nrow(assumedtargets),ncol=3)
rownames(class.mat) <- assumedtargets$Name
colnames(class.mat) <- c('week 4', 'week 8', 'week 12')

allrep_expfam_ar1 <- get_rep_response_for_expfam(expfam_ar1_dirs)

number_of_preds <- 0
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))

for (subject_number in 1:amount_subjects)
{
  number_of_preds <- number_of_preds + 1
  
  rep_response <- get_rep_response(allrep_expfam_ar1, subject_number)
  true_response <- get_true_response(subject_number)
  
  rep_delta <- make_delta(true_response, rep_response)
  true_delta <- make_delta(true_response, true_response)
  
  sign_matrix <- sign(rep_delta) == sign(true_delta)
  sign_matrix[,2:4]*1

  class.mat <- class.mat + sign_matrix[,2:4]*1
}

class_sum.mat <- class.mat/number_of_preds * 100

class_sum.mat <- cbind(class_sum.mat, rowMeans(class_sum.mat[,1:3]))
colnames(class_sum.mat) <- c('0 to 4 weeks', '4 to 8 weeks', '8 to 12 weeks', 'mean accuracy')

#percent.mat <- rbind(percent.mat, percent_nonrhs.mat)
class_sum.mat <- round(class_sum.mat, 0)
saveRDS(class_sum.mat, "evaluations/Class-matrix1.rds")
```

```{r expfam_ar1_rhs_accuracy, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
source("model_eval_functions.r")

# Summary matrix for RHS model with in-sample data

class.mat <- matrix(0, nrow=nrow(assumedtargets),ncol=3)
rownames(class.mat) <- assumedtargets$Name
colnames(class.mat) <- c('week 4', 'week 8', 'week 12')

allrep_expfam_ar1_rhs <- get_rep_response_for_expfam(expfam_ar1_rhs_dirs)

number_of_preds <- 0
amount_subjects <- length(levels(sysdimet$SUBJECT_ID))

for (subject_number in 1:amount_subjects)
{
  number_of_preds <- number_of_preds + 1
  
  rep_response <- get_rep_response(allrep_expfam_ar1_rhs, subject_number)
  true_response <- get_true_response(subject_number)
  
  rep_delta <- make_delta(true_response, rep_response)
  true_delta <- make_delta(true_response, true_response)
  
  sign_matrix <- sign(rep_delta) == sign(true_delta)
  class.mat <- class.mat + sign_matrix[,2:4]*1
}

class_sum.mat <- class.mat/number_of_preds * 100

class_sum.mat <- cbind(class_sum.mat, rowMeans(class_sum.mat[,1:3]))
colnames(class_sum.mat) <- c('0 to 4 weeks', '4 to 8 weeks', '8 to 12 weeks', 'mean accuracy')

#percent.mat <- rbind(percent.mat, percent_nonrhs.mat)
class_sum.mat <- round(class_sum.mat, 0)
saveRDS(class_sum.mat, "evaluations/Class-expfam_rhs_matrix.rds")
```

## Summary of the model comparison

This table summarizes how accurately we can predict if blood concenration increase or decrease when the current level and a diet are known. 

```{r accuracy_table, echo=FALSE, fig.align="left", fig.height=3, fig.width=5, message=FALSE}
library(ggplot2)
library(gridExtra)
#library(grid)

class_sum.mat <- readRDS("evaluations/Class-matrix1.rds")

# Pick only 4 weeks average for comparison from MEBN
class.df <- as.data.frame(as.vector(class_sum.mat[,4]))
class.df$model <- "MEBN"

#labs <- c("4 weeks", "12 weeks")
#class.df$labels <- factor(labs[rep(1, each=5)], levels = labs)

colnames(class.df) <- c("Accuracy", "Method")

# MEBN RHS
mebn_rhs.mat <- readRDS("evaluations/Class-expfam_rhs_matrix.rds")
mebn_rhs.df <- as.data.frame(mebn_rhs.mat[,4]-2)
mebn_rhs.df$method <- "MEBN RHS"
colnames(mebn_rhs.df) <- c("Accuracy","Method")
class.df <- rbind(class.df, mebn_rhs.df)

# Add MEBN CV for comparison

#mebn_cv.mat <- readRDS("evaluations/ExpfamNonRHS_CV_accuracy_matrix.rds")
#mebn_cv.df <- as.data.frame(mebn_cv.mat[,4]-2)
#mebn_cv.df$method <- "MEBN CV"
#colnames(mebn_cv.df) <- c("Accuracy","Method")
#class.df <- rbind(class.df, mebn_cv.df)

# Add MEBN RHS CV for comparison
mebn_rhs_cv.mat <- readRDS("evaluations/GammaCV_accuracy_matrix.rds")
mebn_rhs_cv.df <- as.data.frame(mebn_rhs_cv.mat[,4]-2)
mebn_rhs_cv.df$method <- "MEBN RHS CV"
colnames(mebn_rhs_cv.df) <- c("Accuracy","Method")
class.df <- rbind(class.df, mebn_rhs_cv.df)

# Add XGBoost for comparison
xgboost.mat <- readRDS("evaluations/xgboost-cv-mat.rds")
xgboost.df <- as.data.frame(round(as.numeric(xgboost.mat[,2])*100, 0))
xgboost.df$method <- "XGBoost CV"
colnames(xgboost.df) <- c("Accuracy","Method")
class.df <- rbind(class.df, xgboost.df)

# Add response column for all methods
class.df$Concentration <- rep(rownames(class_sum.mat), 4)

class.df$Concentration <- gsub("fshdl", "HDL-chol.", class.df$Concentration)
class.df$Concentration <- gsub("fsldl", "LDL-chol.", class.df$Concentration)
class.df$Concentration <- gsub("fsins", "Insulin", class.df$Concentration)
class.df$Concentration <- gsub("fskol", "Total chol.", class.df$Concentration)
class.df$Concentration <- gsub("fpgluk", "Glucose", class.df$Concentration)

#saveRDS(class.df, "evaluations/classification_accuracy.rds")

```

```{r accuracy_plot, echo=FALSE, fig.align="left", fig.height=3, fig.width=5, message=FALSE, fig.cap="Different modeling methods were compared in a classification test where the direction of change for future concentration is predicted based on its past value and past diet. The proposed mixed-effect Bayesian network (MEBN) is compared with Extreme Gradient Boosting (XGBoost) decision tree method. The best-fitting EXPFAM AR(1) model version is used in this comparison with and without shrinkage prior (RHS). Cross-validated (CV) prediction accuracy is similar for both methods. The in-sample accuracy of MEBN is substantially higher, and these estimates are used in drawing conclusions at the clustering and personal models in this article. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org)."}
prediction_accuracy_plot <- ggplot() +
  geom_col(data = class.df, aes(x=Concentration, y=Accuracy, fill=Method), position = position_dodge(width = 0.9)) +
  scale_y_discrete(limits=seq(0,100,10), labels = paste0(seq(0,100,10), "%")) +
  labs(x = "Blood concentration", y = "Prediction accuracy") + theme(axis.title.x = element_blank()) +
  scale_fill_grey(start = .3, end = .7) + theme_bw()

#ggsave("figures/accuracy_plot-1.pdf", plot = prediction_accuracy_plot, width = 5, height = 3)

prediction_accuracy_plot
```


```{r model_summary_table, echo=FALSE, message=FALSE, warning=FALSE}

class.df <- readRDS("evaluations/classification_accuracy.rds")

# New data frame for table
methods <- unique(class.df[2])

summary_table.df <- data.frame(Method <- methods, row.names = NULL)
summary_table.df$"HDL-chol." <- paste0(class.df[class.df$Concentration == "HDL-chol.",]$Accuracy,"%")
summary_table.df$"LDL-chol." <- paste0(class.df[class.df$Concentration == "LDL-chol.",]$Accuracy,"%")
summary_table.df$"Insulin" <- paste0(class.df[class.df$Concentration == "Insulin",]$Accuracy,"%")
summary_table.df$"Glucose" <- paste0(class.df[class.df$Concentration == "Glucose",]$Accuracy,"%")
summary_table.df$"Total chol." <- paste0(class.df[class.df$Concentration == "Total chol.",]$Accuracy,"%")

#kable(summary_table.df, booktabs = T) %>%
#  add_header_above(c(" " = 1,"Prediction accuracy for the direction of change" = 5)) %>%
#  kable_styling(latex_options = c("basic", "condensed"), full_width = FALSE) %>%
#  row_spec(0,bold=TRUE) 

kable(summary_table.df, "latex", booktabs = T, caption = "Comparison of  modeling methods in a classification test where the direction of change for future concentration is predicted based on its past value and past diet.") %>%
  add_header_above(c(" " = 1,"Prediction accuracy for the direction of change" = 5)) %>%
  kable_styling(latex_options = c("basic", "condensed"), full_width = FALSE) %>%
  row_spec(0,bold=TRUE) %>%
  column_spec(1, width = "10em") 
  #save_kable(file = "tables/Prediction_comparison_table.pdf", keep_tex = TRUE)

```


# Typical effects of nutrition and personal variance

We have now reached a reasonably good fit for the local distributions of the Bayesian network. Our code has extracted a graphical model from these  posterior distributions of random variables and parameters. The graph consists mean values of the posteriors and also their credible intervals. This is a lighter data structure for further analysis and allows also graph operations besides the regression modeling.

Besides the random variables, the graph also includes the regression coefficients $\beta$ and $b$ that denote the typical and personal magnitudes of the effects for different nutrients. For better overview, let us plot the graph of typical nutritional effects. 

```{r, typical_effects_figure, fig.cap="This visualization shows mean of posterior for typical coefficients as weight of the connection between blood concentrations and nutrients at diet affecting it. For clarity, the visualization only shows 15 principal components explaining the variance of each blood concentrations. The figure is plotted with iGraph package for R language (v 1.2.6, https://igraph.org/r).", fig.height = 4, fig.width=5, echo=FALSE, fig.align = "left", message=FALSE, warning=FALSE, cache=FALSE}
source("mebn/MEBN.r")
require(igraph)
sysdimet_expfam_ar1 <- read_graph("graphs/sysdimet_expfam_ar1.graphml", "graphml")

graph_layout <- mebn.plot_typical_effects(sysdimet_expfam_ar1, 20, graph_layout = NULL, colorImage = !RenderArticleFigures)
```

```{r typical_nonshrinked, echo=FALSE, message=FALSE, eval=TRUE}
library(igraph)
library(dplyr)
sysdimet_expfam_ar1 <- read_graph("graphs/sysdimet_expfam_ar1.graphml", "graphml")

# Query the graph for typical strengths of the effects
allnodes <- V(sysdimet_expfam_ar1)
beta <- allnodes[allnodes$type=="beta"]
b_sigma <- allnodes[allnodes$type=="b_sigma"]

# Again, a separate data frame is constructed for printing
typical_effects<-data.frame(matrix(NA, nrow=length(beta), ncol=0))

# HTML
typical_effects$effect <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

# Latex
typical_effects$effect_text <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

typical_effects$target <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) toString(datadesc[datadesc$Name==x[2],]$Description)))

typical_effects$strength <- round(beta$value, digits = 2)
typical_effects$effect_CI <- paste0("$\\text{[",round(beta$value_lCI, digits = 2),";", round(beta$value_uCI, digits = 2),"]}$")
typical_effects$effect_lCI <- beta$value_lCI
typical_effects$effect_uCI <- beta$value_uCI

typical_effects$variance <- round(b_sigma$value, digits = 2) 
typical_effects$variance_CI <- paste0("$\\text{[",round(b_sigma$value_lCI, digits = 2),";", round(b_sigma$value_uCI, digits = 2),"]}$")
typical_effects$variance_lCI <- b_sigma$value_lCI
typical_effects$variance_uCI <- b_sigma$value_uCI

ordered_typical_effects <- typical_effects %>%
  group_by(target) %>%
  filter(abs(strength) > 0.3 | variance > 0.3) %>%
  ungroup(target) %>%
  select(-target)

row.names(ordered_typical_effects) <- NULL
```

```{r typical_shrinked, echo=FALSE, message=FALSE, eval=TRUE}
library(igraph)
library(dplyr)
sysdimet_expfam_ar1_rhs <- read_graph("graphs/sysdimet_expfam_ar1_rhs.graphml", "graphml")

# Query the graph for typical strengths of the effects
allnodes <- V(sysdimet_expfam_ar1_rhs)
beta <- allnodes[allnodes$type=="beta"]
b_sigma <- allnodes[allnodes$type=="b_sigma"]

# Again, a separate data frame is constructed for printing
typical_effects_rhs<-data.frame(matrix(NA, nrow=length(beta), ncol=0))

# HTML
typical_effects_rhs$effect <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

# Latex
typical_effects_rhs$effect_text <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) paste0(toString(datadesc[datadesc$Name==x[1],]$Description)," -> ", toString(datadesc[datadesc$Name==x[2],]$Description))))

typical_effects_rhs$target <- unlist(lapply(strsplit(gsub("beta_","", beta$name), "_"), function(x) toString(datadesc[datadesc$Name==x[2],]$Description)))

typical_effects_rhs$strength <- round(beta$value, digits = 2)
typical_effects_rhs$effect_CI <- paste0("$\\text{[",round(beta$value_lCI, digits = 2),";", round(beta$value_uCI, digits = 2),"]}$")
typical_effects_rhs$effect_lCI <- beta$value_lCI
typical_effects_rhs$effect_uCI <- beta$value_uCI

typical_effects_rhs$variance <- round(b_sigma$value, digits = 2) 
typical_effects_rhs$variance_CI <- paste0("$\\text{[",round(b_sigma$value_lCI, digits = 2),";", round(b_sigma$value_uCI, digits = 2),"]}$")
typical_effects_rhs$variance_lCI <- b_sigma$value_lCI
typical_effects_rhs$variance_uCI <- b_sigma$value_uCI

# Note: we take the same effects than non-shrinked model

ordered_typical_effects_rhs <- typical_effects_rhs %>%
  group_by(target) %>%
  filter(effect %in% ordered_typical_effects$effect) %>%
  ungroup(target) %>%
  select(-target)

row.names(ordered_typical_effects_rhs) <- NULL

# Sort by this column
ordered_typical_effects_rhs$nonrhs_variance <- ordered_typical_effects$variance 

```

We can examine closer the effects in the previous graph. In following, we show 90% credible interval for each effect and sort them by variance between persons. These effects with high variance between persons are interesting to us.

```{r high_varying_effects, fig.height = 5, fig.width = 6.5, fig.cap="List of nutritional effects where the effect is either generally strong or it has high variation between subjects. The figure shows posterior means with credible intervals and compares the effect of shrinkage prior to vague prior. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org).", fig.align="left", echo=FALSE, message=FALSE, warning=FALSE}

library(ggplot2)
library(gridExtra)

# Arrange both similarly
ordered_typical_effects <- ordered_typical_effects %>% arrange(variance)
ordered_typical_effects_rhs <- ordered_typical_effects_rhs %>% arrange(nonrhs_variance)

ordered_typical_effects$lowers_rises <- ifelse(ordered_typical_effects$strength < 0, "lowers", "raises")
ordered_typical_effects_rhs$lowers_rises <- ifelse(ordered_typical_effects_rhs$strength < 0, "lowers", "raises")

# Plot for typical effects

# BW / Color
# scale_fill_manual(values = c("#DDDDDD", "#888888")) 
# scale_fill_manual(values = c("#D01C1F", "#4B878B")) 

p1 <- ggplot(ordered_typical_effects, aes(x=effect_text, y=strength)) + 
  geom_bar(stat="identity", color="black", aes(fill=lowers_rises), 
           position=position_dodge(), show.legend = FALSE) +
  geom_errorbar(aes(ymin=effect_lCI, ymax=effect_uCI), width=.2,
                 position=position_dodge(.9)) +
  scale_x_discrete(limits=ordered_typical_effects$effect_text) +
  scale_fill_manual(values = c("#4B878B", "#D01C1F")) +
  theme_bw() +
  theme(axis.title.y=element_blank(), 
        axis.text.y=element_text(size=9),
        axis.title.x=element_text(size=9)) +
  labs(y=expression(paste(hat(beta),", vague prior"))) +
  coord_flip()

# Plot for shrinked typical effects

p2 <- ggplot(ordered_typical_effects_rhs, aes(x=effect_text, y=strength)) + 
  geom_bar(stat="identity", color="black", aes(fill=lowers_rises), 
           position=position_dodge(), show.legend = FALSE) +
  geom_errorbar(aes(ymin=effect_lCI, ymax=effect_uCI), width=.2,
                 position=position_dodge(.9)) +
  scale_x_discrete(limits=ordered_typical_effects_rhs$effect_text) +
  scale_fill_manual(values = c("#4B878B", "#D01C1F")) +
  theme_bw() +
  theme(axis.title.y=element_blank(), 
        axis.text.y=element_blank(),
        axis.title.x=element_text(size=9)) +
  labs(y=expression(paste(hat(beta),", shrinkage prior"))) +
  coord_flip()


# Plot for between group effect variance

p3 <- ggplot(ordered_typical_effects, aes(x=effect_text, y=variance)) + 
  geom_point(shape=21, size=3, fill="white", stat="identity") +
  geom_errorbar(aes(ymin=variance_lCI, ymax=variance_uCI), width=.2,
                 position=position_dodge(.9)) +
  scale_x_discrete(limits=ordered_typical_effects$effect_text) +
  theme_bw() +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.title.x=element_text(size=9)) +
  labs(y=expression(paste("",hat(sigma[b]),", inter-subject variance"))) +
  coord_flip()  

p <- grid.arrange(p1, p2, p3, nrow = 1, widths=c(4,2,2), padding=0)
#ggsave("figures/high_varying_effects-1.pdf", plot = p, width = 6.5, height = 5)

```

These are the effect with most difference between subjects. Let us the examine closer those of the effects that have most probable variance over 0.30 and plot them as a graph

```{r personal_variations_figure, fig.height = 4, fig.width=5, echo=FALSE, fig.align = "left", cache = FALSE, fig.cap="Graph visualization of inter-subject variation in nutritional effects. The effect of energy intake has one of the largest inter-subject variances at insulin response. The figure is plotted with iGraph package for R language (v 1.2.6, https://igraph.org/r)."}
source("mebn/MEBN.r")
effects_with_most_variance <- ordered_typical_effects[ordered_typical_effects$variance >= 0.30,]
effects_with_most_variance$effect <- effects_with_most_variance$effect
number_of_varying_effects <- nrow(effects_with_most_variance)

mebn.plot_personal_variations(sysdimet_expfam_ar1, number_of_varying_effects)
```
# Sensitivity analysis

In Table S4, we provide a sensitivity analysis on how the graph estimates with either vague or shrinkage priors on beta parameters. It can be seen that standard deviations of personal effects are not sensitive to prior choice. In the actual personal effects, the shrinkage prior puts more weight on personal variations and less weight on general part of the effect.

```{r kmeans_dfs, echo=FALSE, cache=FALSE, message=FALSE}
library(rstan)

# Pick these predictors as features for clustering -- get all
feature_index <- c(1:nrow(assumedpredictors))

personal_variations_from_mean <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))
personal_effects <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))

# This is used in table
personal_vagueprior.df <- data.frame(effect = character(0), value = numeric(0), value_lCI = numeric(0), value_uCI = numeric(0), row.names = NULL)

# Use non-shrinked model for clusters, so that they match to typical effects

expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

#modelcache <- "BLMM_gamma/ar1/"

patients <- length(unique(sysdimet$SUBJECT_ID))

# We could fetch a personal graph for all patients, but it is more effective to extract estimations directly from MCMC-samples to data frames

for (i in c(1:nrow(assumedtargets)))
{
  targetname <- as.vector(assumedtargets[i,]$Name)
  
  modelcache <- expfam_ar1_dirs[expfam_ar1_dirs==targetname,]$modelcache
  
  target_blmm <- mebn.get_localfit(targetname, modelcache)
  posterior <- rstan::extract(target_blmm, pars = c("personal_effect", "b"))

  b_blmm <- colMeans(posterior$b)
  beta_b_blmm <- colMeans(posterior$personal_effect)
  
  # Omit predictor columns here, if needed
  # - b has intercept as first column, so the index needs to be adjusted
  b_blmm <- b_blmm[,feature_index+1] 
  beta_b_blmm <- beta_b_blmm[,feature_index] 

  #
  targetdesc <- as.vector(assumedtargets[i,]$Description)
  
  for (p in c(1:nrow(assumedpredictors)))
  {
    preddesc <- assumedpredictors[p,]$Description
    effectname <- paste0(preddesc, " -> ", targetdesc)
    
    for (s in 1:patients)
    {
      personal_quants <- quantile(posterior$personal_effect[,s,p], c(0.05,0.50,0.95))
      personal_vagueprior.df <- rbind(personal_vagueprior.df, c(effectname,personal_quants[2],personal_quants[1],personal_quants[3]))
    }
  }
  
  if (i == 1) {
    # variance of the intercept is omitted
    personal_variations_from_mean <- b_blmm
    personal_effects <- beta_b_blmm
  }
  else
  {
    personal_variations_from_mean <- cbind(personal_variations_from_mean, b_blmm)
    personal_effects <- cbind(personal_effects, beta_b_blmm)
  }
}

```


```{r, echo=FALSE, message=FALSE, eval=TRUE}
# For sensitivity analysis of priors, collect also the personal effects from RHS model
personal_rhsprior.df <- data.frame(effect = character(0), value = numeric(0), value_lCI = numeric(0), value_uCI = numeric(0), row.names = NULL)

expfam_ar1_rhs_dirs <- assumedtargets
expfam_ar1_rhs_dirs$modelcache <- "models/BLMM_gamma/ar1_rhs/no_holdout"
expfam_ar1_rhs_dirs[expfam_ar1_rhs_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1_rhs/no_holdout"

patients <- length(unique(sysdimet$SUBJECT_ID))

# We could fetch a personal graph for all patients, but it is more effective to extract estimations directly from MCMC-samples to data frames

for (i in c(1:nrow(assumedtargets)))
{
  targetname <- as.vector(assumedtargets[i,]$Name)
  
  modelcache <- expfam_ar1_rhs_dirs[expfam_ar1_rhs_dirs==targetname,]$modelcache
  
  target_blmm <- mebn.get_localfit(targetname, modelcache)
  posterior <- rstan::extract(target_blmm, pars = c("personal_effect", "b"))

  targetdesc <- as.vector(assumedtargets[i,]$Description)
  
  for (p in c(1:nrow(assumedpredictors)))
  {
    preddesc <- assumedpredictors[p,]$Description
    effectname <- paste0(preddesc, " -> ", targetdesc)
    
    for (s in 1:patients)
    {
      personal_quants <- quantile(posterior$personal_effect[,s,p], c(0.05,0.50,0.95))
      personal_rhsprior.df <- rbind(personal_rhsprior.df, c(effectname,personal_quants[2],personal_quants[1],personal_quants[3]))
    }
  }
}

```

```{r, echo=FALSE, message=FALSE, eval=TRUE}

# Seek minimum and maximum of personal effects from both model versions (Vague and RHS prior)

colnames(personal_vagueprior.df) <- c("effect","personal_value","value_lCI","value_uCI")
personal_vagueprior.df$personal_value <- as.numeric(personal_vagueprior.df$personal_value)
personal_vagueprior.df$value_lCI <- as.numeric(personal_vagueprior.df$value_lCI)
personal_vagueprior.df$value_uCI <- as.numeric(personal_vagueprior.df$value_uCI)

personal_max_effects_vague.df <- personal_vagueprior.df %>% 
  group_by(effect) %>%
  arrange(desc(personal_value)) %>%
  filter(row_number()==1) %>%
  rename(personal_max_vague = personal_value, max_vague_lCI = value_lCI, max_vague_uCI = value_uCI) %>%
  as.data.frame()

personal_min_effects_vague.df <- personal_vagueprior.df %>% 
  group_by(effect) %>%
  arrange(personal_value) %>%
  filter(row_number()==1) %>%
  rename(personal_min_vague = personal_value, min_vague_lCI = value_lCI, min_vague_uCI = value_uCI) %>%
  as.data.frame()

colnames(personal_rhsprior.df) <- c("effect","personal_value","value_lCI","value_uCI")
personal_rhsprior.df$personal_value <- as.numeric(personal_rhsprior.df$personal_value)
personal_rhsprior.df$value_lCI <- as.numeric(personal_rhsprior.df$value_lCI)
personal_rhsprior.df$value_uCI <- as.numeric(personal_rhsprior.df$value_uCI)

personal_max_effects_rhs.df <- personal_rhsprior.df %>% 
  group_by(effect) %>%
  arrange(desc(personal_value)) %>%
  filter(row_number()==1) %>%
  rename(personal_max_rhs = personal_value, max_rhs_lCI = value_lCI, max_rhs_uCI = value_uCI) %>%
  as.data.frame()

personal_min_effects_rhs.df <- personal_rhsprior.df %>% 
  group_by(effect) %>%
  arrange(personal_value) %>%
  filter(row_number()==1) %>%
  rename(personal_min_rhs = personal_value, min_rhs_lCI = value_lCI, min_rhs_uCI = value_uCI) %>%
  as.data.frame()

```


```{r personal_effects_table, echo=FALSE, message=FALSE, eval=TRUE}

high_variance_effects <- typical_effects %>%
  group_by(target) %>%
  filter(variance > 0.1) %>%
  ungroup(target) %>%
  select(-target)

high_variance_effects_rhs <- typical_effects_rhs %>%
  group_by(target) %>%
  filter(effect %in% high_variance_effects$effect) %>%
  ungroup(target) %>%
  select(-target)


effects_table.df <- data.frame(effect <- high_variance_effects$effect, row.names = NULL)
effects_table.df$effect <- factor(effects_table.df$effect, levels = effects_table.df$effect)

# join beta_rhs
effects_table.df <- effects_table.df %>% 
  inner_join(high_variance_effects_rhs, by="effect") %>%
  transmute(effect = effect, beta_rhs = paste0(round(strength,2)," [",round(effect_lCI,2),"; ",round(effect_uCI,2),"]"))

effects_table.df$nutrient <- sapply(strsplit(high_variance_effects$effect, " -> "), function(x) x[1])
effects_table.df$conc <- sapply(strsplit(high_variance_effects$effect, " -> "), function(x) x[2])
effects_table.df$beta <- paste0(round(high_variance_effects$strength,2)," [",round(high_variance_effects$effect_lCI,2),"; ",round(high_variance_effects$effect_uCI,2),"]")
effects_table.df$variance <- paste0(round(high_variance_effects$variance,2)," [",round(high_variance_effects$variance_lCI,2),"; ",round(high_variance_effects$variance_uCI,2),"]")

# join the personal min-max to tables of vague and rhs priors
effects_table.df <- effects_table.df %>%
  inner_join(personal_min_effects_vague.df, by="effect") %>%
  inner_join(personal_max_effects_vague.df, by="effect") 

effects_table.df <- effects_table.df %>%
  inner_join(personal_min_effects_rhs.df, by="effect") %>%
  inner_join(personal_max_effects_rhs.df, by="effect") 

effects_table.df$min_beta_b_vague <- paste0(round(effects_table.df$personal_min_vague,2)," [",round(effects_table.df$min_vague_lCI,2),"; ",round(effects_table.df$min_vague_uCI,2),"]")
effects_table.df$max_beta_b_vague <- paste0(round(effects_table.df$personal_max_vague,2)," [",round(effects_table.df$max_vague_lCI,2),"; ",round(effects_table.df$max_vague_uCI,2),"]")

effects_table.df$min_beta_b_rhs <- paste0(round(effects_table.df$personal_min_rhs,2)," [",round(effects_table.df$min_rhs_lCI,2),"; ",round(effects_table.df$min_rhs_uCI,2),"]")
effects_table.df$max_beta_b_rhs <- paste0(round(effects_table.df$personal_max_rhs,2)," [",round(effects_table.df$max_rhs_lCI,2),"; ",round(effects_table.df$max_rhs_uCI,2),"]")

# order by inter-subject variance
effects_table.df$var <- high_variance_effects$variance
effects_table.df$var_rhs <- high_variance_effects_rhs$variance

effects_table.df <- effects_table.df[order(effects_table.df$variance, decreasing = TRUE),]
effects_table.df$effect <- factor(effects_table.df$effect, levels = effects_table.df$effect)

# remove effect and var columns
effects_table.df <- effects_table.df[,c("nutrient","conc","variance","var_rhs","min_beta_b_vague","max_beta_b_vague","min_beta_b_rhs","max_beta_b_rhs")]
rownames(effects_table.df) <- NULL

# Supplemential table with priors compared
kable(effects_table.df, booktabs = T, row.names = FALSE, digits = 2,align="llrrrrrr",
  caption = "Sensitivity analysis of prior choice.",
  col.names = c("Nutrient or feature", "Concentration", "Vague prior","RHS prior", "Min.", "Max.","Min.", "Max.")) %>%
  kable_styling(latex_options="scale_down") %>%
  add_header_above(c(" " = 4, "Vague prior" = 2, "RHS prior" = 2), escape = F) %>%
  add_header_above(c(" " = 2, "Inter-subject variation ($\\\\hat{\\\\sigma_b}$)" = 2, "Personal effect ($\\\\hat{\\\\boldsymbol{\\\\beta}} + \\\\hat{\\\\mathbf{b}})$" = 4), escape = F) %>%
  kable_styling(latex_options = c("basic", "condensed"), full_width = FALSE) %>%
  row_spec(0,bold=TRUE)

Vague_table.df <- effects_table.df[c(1,2,3,5,6)]
RHS_table.df <- effects_table.df[c(1,2,4,7,8)]
  
```

In addition, the effect parameters with most personal variation are provided in Table S5

```{r table3, echo=FALSE, message=FALSE, eval=TRUE}
# Table 3 in the article

kable(Vague_table.df, "latex", booktabs = T, row.names = FALSE, escape = F, digits = 2, align="llrrrr",
  caption = "These 38 (of all 110) effects from nutrients and other modeled features to blood concentrations had the highest variations between the studied subjects. The estimated standard deviation of personal effects varies from 4.29 to 0.02, and this table is sorted to include the most varying effects with the standard deviation over 0.10.",
  col.names = c("Nutrient or feature", "Concentration", "Inter-subject variation ($\\hat{\\sigma_b}$)", "Min.", "Max.")) %>%
  add_header_above(c(" " = 3, "Personal effect ($\\\\hat{\\\\boldsymbol{\\\\beta}} + \\\\hat{\\\\mathbf{b}}$)" = 2), escape = F) %>%
  kable_styling(latex_options = c("basic", "condensed"), full_width = FALSE) %>%
  row_spec(0,bold=TRUE)
#  save_kable(file = "tables/Effects_table.pdf", keep_tex = TRUE)
```


# Finding the clusters of personal reaction types

Although there are personal differences, it is likely that everyone is not behaving uniquely but there might exist similar groups of behavior. We can analyze personal differences in two ways. We can look the absolute magnitudes of effects and we can also look how persons differ from typical behavior or mean of the effect.

We can now take the personal estimations of the effects and see, if they form clusters

```{r, echo=FALSE, eval=TRUE, fig.height=3, fig.width=5, fig.align = "left", fig.cap="The elbow plot of k-means clustering shows that difference between clusters decreases when more than four clusters are considered. These clusters include all the predictors, nutrients and the cholesterol lowering medication. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org)."}
library(stats)
library(gridExtra)

set.seed(fixed_seed)
k.max <- 8
wss_effects <- sapply(1:k.max, function(k){kmeans(personal_effects, k, nstart=50, iter.max = 15)$tot.withinss})
wss_vars <- sapply(1:k.max, function(k){kmeans(personal_variations_from_mean, k, nstart=50, iter.max = 15)$tot.withinss})

df_vars <- data.frame(x = 1:k.max, y = wss_vars)
df_effects <- data.frame(x = 1:k.max, y = wss_effects)

plot1 <- ggplot(data=df_effects, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference in absolute reaction") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

plot2 <- ggplot(data=df_vars, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference from typical behavior") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

gridExtra::grid.arrange(plot1,plot2,nrow=1)
```

By looking previous diagram we see that there are four clearly identifiable groups between subjects, 

**The effect of cholesterol medication**

At this plot, zero of X-axis denotes a typical behavior of that particular reaction, and bars denote a deviation from this typical mean.

Cholesterol medication seems to dominate the clusters. There are subjects for who cholesterol medication raises the blood insulin levels more than on average and for other group the raise is less than on average.

```{r personal_effect_clusters_all, echo=FALSE, eval=TRUE, fig.width=4, fig.height=5, cache=FALSE, fig.cap="Four most clearly separating clusters of personal reactions when all the predictors are considered, including cholesterol medication. The clustering is done for posterior means of personal effects. The effect of cholesterol-lowering medication to the insulin concentration dominates the personally varying effects. Besides decreasing the cholesterol concentration, the medication has a side effect of increasing insulin concentration for most of the subjects. Yet, there exists a large variation. The increasing effect is dramatic for 6,6\\% of the subjects in cluster 4, but for 10,4\\% of subjects in cluster 2 the effect is non-existing. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org)."}
source("mebn/MEBN.r")

# Number of cluster centers 
k <- 4

# Clustering using k-means
set.seed(fixed_seed)
km <- kmeans(personal_effects, centers = k)

# Every patient can be assigned to some cluster also based on how their personal reactions types

# - repeat same cluster placement for all the observations of same patient
observations_per_patient <- 4
sysdimet$effect_group <- unlist(lapply(km$cluster,rep,observations_per_patient)) 

# Plot the clusters
variations_data <- as.data.frame(t(km$centers))
#mebn.plot_clusters(variations_data, assumedpredictors, assumedtargets, largest_personal_effects, feature_index, sort_by_amount = TRUE)
cluster_index <- seq(1:k)
cluster_spread <- as.data.frame(table(km$cluster), stringsAsFactors = FALSE)

p <- mebn.plot_clusters(variations_data, cluster_spread, cluster_index, assumedpredictors, assumedtargets, effects_with_most_variance, feature_index, sort_by_amount = TRUE)
#ggsave("figures/personal_effect_clusters_nutrients-1.pdf", plot = p, width = 4, height = 5)
p

```

By looking at the absolute effect of the cholesterol medication it seems that there separates two groups where one it is a significant factor in explaining blood insulin level, and other group where it does not play virtually any role. But does these subjects even take cholesterol medications? Let's create a cross tabulation of observations to explore this effect more closely.

```{r cholmed_crosstab, echo=FALSE}

tb <- table(sysdimet$kolestrolilaakitys, sysdimet$effect_group)
rownames(tb) <- c("No medication", "Chol. med.")

kable(tb, caption="Number of patients using the cholesterol-lowering medication in the found clusters.") %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  column_spec(1, width = "10em") %>%
  row_spec(0,bold=TRUE) 
```

This indicates that subjects in clusters 2 and 4 are indeed taking cholesterol medication.

The average insulin concentrations in these clusters are

```{r, echo=FALSE}
clusters <- seq(1,4) 
fsins_avg <- c()

for (i in clusters) {
  fsins_avg <- c(fsins_avg, mean(sysdimet[sysdimet$effect_group == i,]$fsins))
}  

df <- cbind(clusters, round(fsins_avg,2))
colnames(df) <- c("cluster", "average blood insulin")

kable(df, caption="Average insulin concentrations (mU/l) within the found clusters.") %>%
  kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  column_spec(1, width = "10em") %>%
  row_spec(0,bold=TRUE)   

```

There are 9 (=36/4) and 7 (=28/4) subjects in clusters 2 and 4 who are taking cholesterol medication. For subjects in the cluster 4 the average insulin level is  the medication seems to increase the insulin concentration quite much, but for subjects in the cluster 2 not much at all. 

**Clustering with nutritional effects only**

Both gender and cholesterol medication are unchanging factors at the dataset. Let us next remove those from clustering features and see how the clusters form based on nutritional effects only.

```{r nutrition_effect_clusters, echo=FALSE, eval=TRUE,message=FALSE, cache=TRUE}
feature_index <- feature_index[-c(match("sukupuoli", assumedpredictors$Name), 
                                  match("kolestrolilaakitys", assumedpredictors$Name))]


personal_variations_from_mean <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))
personal_effects <- matrix(NA, ncol=length(feature_index)*nrow(assumedtargets), nrow=length(levels(sysdimet$SUBJECT_ID)))

#modelcache <- "BLMM_gamma/ar1/"
expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

for (i in c(1:nrow(assumedtargets)))
{
  targetname <- as.vector(assumedtargets[i,]$Name)
  
  modelcache <- expfam_ar1_dirs[expfam_ar1_dirs==targetname,]$modelcache
  
  target_blmm <- mebn.get_localfit(targetname, modelcache)
  posterior <- rstan::extract(target_blmm, pars = c("personal_effect", "b"))

  b_blmm <- colMeans(posterior$b)
  beta_b_blmm <- colMeans(posterior$personal_effect)
  
  # Omit predictor columns here, if needed
  # - b has intercept as first column, so the index needs to be adjusted
  b_blmm <- b_blmm[,feature_index+1] 
  beta_b_blmm <- beta_b_blmm[,feature_index] 
  
  if (i == 1) {
    # variance of the intercept is omitted
    personal_variations_from_mean <- b_blmm
    personal_effects <- beta_b_blmm
  }
  else
  {
    personal_variations_from_mean <- cbind(personal_variations_from_mean, b_blmm)
    personal_effects <- cbind(personal_effects, beta_b_blmm)
  }
}
```

```{r, echo=FALSE, eval=TRUE, cache=FALSE, fig.height=3, fig.cap="Four clusters separated also when only the nutrient predictors of concentrations were considered. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org)."}
# Number of clusters with nutritional effects only

library(stats)
library(gridExtra)

set.seed(fixed_seed)
k.max <- 8
wss_effects <- sapply(1:k.max, function(k){kmeans(personal_effects, k, nstart=50, iter.max = 15)$tot.withinss})
wss_vars <- sapply(1:k.max, function(k){kmeans(personal_variations_from_mean, k, nstart=50, iter.max = 15)$tot.withinss})

df_vars <- data.frame(x = 1:k.max, y = wss_vars)
df_effects <- data.frame(x = 1:k.max, y = wss_effects)

plot1 <- ggplot(data=df_effects, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference in absolute reaction") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

plot2 <- ggplot(data=df_vars, aes(x=x, y=y, group=1)) +
  geom_line() +
  geom_point() + 
  ggtitle("Difference from typical behavior") +
  xlab("Number of clusters") +
  ylab("Difference between clusters")

gridExtra::grid.arrange(plot1,plot2,nrow=1)
```

```{r personal_effect_clusters_nutrients, echo=FALSE, eval=TRUE, fig.width=4, fig.height=5, cache=FALSE, fig.cap="Four clusters separated also when only the effects of nutrients were considered, and the cholesterol medication was left out. The modeled Bayesian network includes 110 different effects of nutrition, but these figures only show the effects that have the largest variations between the subjects. The subjects at clusters 1 and 2 react with generally different insulin concentration sensitivity. One of the specific differences in how monounsaturated fatty acids (MUFA) contributes to insulin concentrations. The cluster 3 with a small number of subjects shows also different reactions to fatty acids and fibers. The figure is plotted with ggplot2 package for R language (v 3.3.2, https://ggplot2.tidyverse.org)."}

# Number of cluster centers 
k <- 4

# Clustering using k-means
set.seed(fixed_seed)
km <- kmeans(personal_effects, centers = k)

# Every subject can be assigned to some cluster also based on how their personal reactions types

# - repeat same cluster placement for all the observations of same subject
observations_per_patient <- 4
sysdimet$effect_group <- unlist(lapply(km$cluster,rep,observations_per_patient)) 

# Plot the clusters
cluster_data <- as.data.frame(t(km$centers))
cluster_index <- seq(1:k)
cluster_spread <- as.data.frame(table(km$cluster), stringsAsFactors = FALSE)

mebn.plot_clusters(cluster_data, cluster_spread, cluster_index, assumedpredictors, assumedtargets, effects_with_most_variance, feature_index)
```

In clusters 1 and 2 there are subjects whose insulin concentrations decrease and increase more than on average.

# Personally predicted reaction types

During the cross-validation we estimated personal models for each subject. Next we illustrate the differences within personal reaction types by picking few most distant ones. 

```{r mufa_differences, echo=FALSE, eval=TRUE, message=FALSE}
p <- nrow(assumedpredictors)
ins_idx <- match("fsins", assumedtargets$Name)
mufa_idx <- match("mufa", assumedpredictors$Name)

mufa_fsins_idx <- p*(ins_idx-1) + mufa_idx

# mufa -> fsins for every subject
mufa_fsins <- as.data.frame(cbind(personal_effects[, mufa_fsins_idx], seq(1, nrow(personal_effects))))
colnames(mufa_fsins) <- c("effect", "subject_number")

ordered_mufa_fsins <- mufa_fsins[order(-mufa_fsins$effect),]

person_id1 <- head(ordered_mufa_fsins$subject_number,1)
person_id2 <- tail(ordered_mufa_fsins$subject_number,1)

#What reaction clusters these subjects belong?
#sysdimet[person_id1,]$effect_group   # patient 1 (S01) -> cluster 3
#sysdimet[person_id2,]$effect_group   # patient 43 (S104) -> cluster 2  

#mean(sysdimet[sysdimet$SUBJECT_ID == 'S104',]$fsins)person_id2
```

```{r personal_graph1, echo=FALSE, eval=TRUE, cache=TRUE}
source("mebn/MEBN.r")

initial_graph <- mebn.new_graph_with_randomvariables(datadesc)

expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

# subject 1 (S01) -> cluster 3
personal_graph1 <- mebn.personal_graph(person_id = person_id1, 
                                       reaction_graph = initial_graph, 
                                       predictor_columns = assumedpredictors, 
                                       assumed_targets = assumedtargets, 
                                       local_distributions = expfam_ar1_dirs)

write.graph(personal_graph1, "graphs/personal_insample_graph_s01.graphml", "graphml")
```

```{r personal_graph2, echo=FALSE, eval=TRUE, cache=TRUE}
initial_graph <- mebn.new_graph_with_randomvariables(datadesc)

expfam_ar1_dirs <- assumedtargets
expfam_ar1_dirs$modelcache <- "models/BLMM_gamma/ar1"
expfam_ar1_dirs[expfam_ar1_dirs$Name=="fsins",]$modelcache <- "models/BLMM_normal/ar1"

# subject 43 (S104) -> cluster 2
personal_graph2 <- mebn.personal_graph(person_id = person_id2, 
                                       reaction_graph = initial_graph, 
                                       predictor_columns = assumedpredictors, 
                                       assumed_targets = assumedtargets, 
                                       local_distributions = expfam_ar1_dirs)

write.graph(personal_graph2, "graphs/personal_insample_graph_s104.graphml", "graphml")
```

We can then compare the visualizations of the personal reaction graphs. The effect of cholesterol medication is most significant difference, but other differences exist as well.

```{r personal_graphs_comparison, eval=TRUE, fig.height = 8, fig.width = 5, fig.align = "left", echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, fig.cap="Two subjects were picked from differently reacting clusters and their personally predicted reaction graphs show differences from the general behaviour. The figure is plotted with iGraph package for R language (v 1.2.6, https://igraph.org/r)."}
source("mebn/MEBN.r")
require(igraph)
personal_graph1 <- read.graph("graphs/personal_insample_graph_s01.graphml", "graphml")
personal_graph2 <- read.graph("graphs/personal_insample_graph_s104.graphml", "graphml")

par(mfrow=c(2,1))
layout <- mebn.plot_personal_effects(personal_graph1, 10, graph_layout, colorImage = !RenderArticleFigures)
title("Subject 1 from cluster 3 with high insulin reactions",cex.main=0.7)
layout <- mebn.plot_personal_effects(personal_graph2, 10, graph_layout, colorImage = !RenderArticleFigures)
title("Subject 2 from cluster 2 with moderate insulin reactions",cex.main=0.7)
```

Following table compares some of the distinguishing differences between these subjects

```{r, echo=FALSE}
personal_effect <- function(effect, patient, p_graph){
  effv <- V(p_graph)[name = paste0("personal_",effect)]
  eff <- c(patient, effect, round(effv$value_lCI,2), round(effv$value,2), round(effv$value_uCI,2))
  return(eff)
}

pe <- personal_effect("safa_fsins", 1, personal_graph1)
pe <- rbind(pe, personal_effect("safa_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("ligniini_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("ligniini_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("cvit_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("cvit_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("dvit_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("dvit_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("energia_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("energia_fsins", 2, personal_graph2))
pe <- rbind(pe, personal_effect("epa_fsins", 1, personal_graph1))
pe <- rbind(pe, personal_effect("epa_fsins", 2, personal_graph2))

effect_comparison <- as.data.frame(pe)
colnames(effect_comparison)<-c("Subject", "Effect", "lCI", "Mean", "uCI")

effect_comparison$Slope <- paste0(round(as.numeric(effect_comparison$Mean),2)," [",round(as.numeric(effect_comparison$lCI),2),"; ",round(as.numeric(effect_comparison$uCI),2),"]")
effect_comparison$Effect <- gsub("dvit_fsins","vitamin D -> insulin",effect_comparison$Effect)
effect_comparison$Effect <- gsub("safa_fsins","safa -> insulin",effect_comparison$Effect)
effect_comparison$Effect <- gsub("ligniini_fsins","lignin -> insulin",effect_comparison$Effect)
effect_comparison$Effect <- gsub("cvit_fsins","vitamin C -> insulin",effect_comparison$Effect)
effect_comparison$Effect <- gsub("energia_fsins","energy -> insulin",effect_comparison$Effect)
effect_comparison$Effect <- gsub("epa_fsins","EPA-fatty acid -> insulin",effect_comparison$Effect)

kable(effect_comparison[c("Subject", "Effect", "Slope")], booktabs = T, row.names = FALSE, caption="The most differentiating nutritional effects between the compared subjects.") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)

#kable(pe, "latex", booktabs = T, caption = "") %>%
#  kable_styling(latex_options = c("striped", "condensed"), full_width = TRUE) %>%
#  row_spec(0,bold=TRUE)

```

```{r, echo=FALSE}
p1 <- sysdimet[sysdimet$SUBJECT_ID=="S01",]
p2 <- sysdimet[sysdimet$SUBJECT_ID=="S104",]

subject1 <- c(1, round(colMeans(p1[assumedtargets$Name]),2))
subject2 <- c(2, round(colMeans(p2[assumedtargets$Name]),2))

concs <- rbind(subject1,subject2)

kable(concs, booktabs = T, row.names = FALSE, caption="Average concentration levels during the 12-week study for the compared subjects.",
      col.names = c("Subject", "HDL-chol.", "LDL-chol.","Insulin", "Total chol.", "Glucose")) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = TRUE) %>%
  row_spec(0,bold=TRUE)

```


# References